{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aparnasree2020/CAS_RPM_2023_GBM/blob/main/Copy_of_Playground2_Run_Models_compare_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xiri0H-FVwo"
      },
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWqpTZ-pFVNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a742edf0-22e1-4bde-e48f-042c1b46fd00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time <- Sys.time()\n",
        "# Comment after installation so that the whole notebook can be run in one go\n",
        "install.packages('xgboost')\n",
        "install.packages('ggplot2')\n",
        "install.packages('plotly')\n",
        "install.packages('pROC')\n",
        "install.packages('lightgbm')\n",
        "#install.packages('shapper')\n",
        "install.packages(\"caret\")\n",
        "install.packages('gbm')\n",
        "install.packages(\"knitr\")\n",
        "end_time <- Sys.time()\n",
        "elapsed_time <- difftime(end_time, start_time, units = \"secs\")\n",
        "print(paste(\"Installation of libraries took: \", round(elapsed_time/60, 2), \" minutes\"))\n",
        "\n",
        "# \"Installation of libraries took:  25.16  minutes\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('reshape2')\n",
        " "
      ],
      "metadata": {
        "id": "KHY7olMNLvwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znex9RXrOkLp"
      },
      "outputs": [],
      "source": [
        "#Todo \n",
        "# Add time taken by each model\n",
        "# Predict on train data so that overfitting can be estimated / understood\n",
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY33DK77FeAP"
      },
      "source": [
        "# Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(dplyr)\n",
        "library(tidyverse)\n",
        "library(xgboost)\n",
        "library(ggplot2)\n",
        "\n",
        "library(gbm)\n",
        "library(lightgbm)\n",
        "\n",
        "library(knitr)\n",
        "library(plotly)\n",
        "library(pROC)\n",
        "\n",
        "library(caret)\n",
        "library(knitr)\n",
        "\n",
        "library(reshape2 )\n",
        "#library(gt)\n",
        "#library(measures)"
      ],
      "metadata": {
        "id": "71MIFGkQawGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmtw_z4vFi5_"
      },
      "source": [
        "# Load CSV datafile - Data split as train and test (80/20 split) and stored in git\n",
        "\n",
        "*   Train data - Used for model training\n",
        "*   Test data - Hold out data used for evaluating model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIWTJj6udY-K"
      },
      "outputs": [],
      "source": [
        "train_file <- \"https://raw.github.com/aparnasree2020/sampledata_casws/master/Unbalanced_train_clean.csv\"\n",
        "test_file <- \"https://raw.github.com/aparnasree2020/sampledata_casws/master/Unbalanced_test_clean.csv\"\n",
        "train_data <- read.csv(file =train_file, header = TRUE )\n",
        "test_data <- read.csv(file =test_file, header = TRUE )\n",
        "x_train <- train_data[, !names(train_data) %in% \"claim_count_pd\"]\n",
        "y_train <- train_data$claim_count_pd\n",
        "x_test <- test_data[, !names(test_data) %in% \"claim_count_pd\"]\n",
        "y_test <- test_data$claim_count_pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FoeSDqRVNXJ"
      },
      "source": [
        "#XGboost with standard hyperparameters ( no tuning) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx9D2hAqIqr_"
      },
      "outputs": [],
      "source": [
        "print(colnames(x_train))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain <- xgb.DMatrix(data = as.matrix(x_train)\n",
        "                        , label = y_train\n",
        "  )\n",
        "  dtest <- xgb.DMatrix(data = as.matrix(x_test)\n",
        "                       , label = y_test\n",
        "  )"
      ],
      "metadata": {
        "id": "U18zbPH67_54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_weight <- sum(y_train == 0) / sum(y_train == 1)\n",
        "print(pos_weight)\n",
        "fit <- xgboost(data = dtrain, nrounds = 500, objective = \"binary:logistic\", eta = 0.3, max_depth = 6,eval_metric = \"auc\",scale_pos_weight = pos_weight,silent = 1,verbose = 0)\n",
        "pred_y_test <- predict(fit, dtest) # Predict the classes for the test data\n",
        "pred_y_test_bin = ifelse(pred_y_test > 0.5, 1, 0)\n",
        "dataout_XGboost_simple <- data.frame(pred_y_test_bin, y_test)\n",
        "roc <- roc(y_test, pred_y_test_bin)\n",
        "print(roc)"
      ],
      "metadata": {
        "id": "Msl-7khZ7Gny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_matrix <- xgb.importance(colnames(dtrain), model = fit)\n",
        "importance_matrix <- subset(importance_matrix, select = c(Feature,Gain))\n",
        "  \n",
        "xgb.plot.importance(importance_matrix) \n",
        "top_10_features <- head(importance_matrix$Feature, 20)"
      ],
      "metadata": {
        "id": "OycN34Zs-vX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_10_features)"
      ],
      "metadata": {
        "id": "OnA6a5A2qlQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_top10 <- x_train[, c(top_10_features)]\n",
        "x_test_top10 <- x_test[, c(top_10_features)]\n",
        "#print(x_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "N01Y9wb7VD9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a GLM\n",
        "weight_vector <- ifelse(y_train == 1, 10, 1)\n",
        "fit <- step(glm(y_train ~ ., data = x_train_top10, family = \"gaussian\"), direction = \"both\", trace = FALSE,weights = weight_vector)\n",
        "pred_y_test <- predict(fit, newdata = x_test_top10, type = \"response\")\n",
        "pred_y_test_bin = ifelse(pred_y_test > 0.1, 1, 0)\n",
        "dataout_GLM_top10 <- data.frame(pred_y_test_bin, y_test)"
      ],
      "metadata": {
        "id": "FOi7SaRjYbHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJiQp06OEcFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_vector"
      ],
      "metadata": {
        "id": "lQBxKgJEKRTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist(pred_y_test)"
      ],
      "metadata": {
        "id": "FZD3b7101LC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat <- table(y_test, pred_y_test_bin)\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "LXLArrNn1WS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a GLM\n",
        "fit <- step(glm(y_train ~ ., data = x_train, family = \"gaussian\"), direction = \"both\", trace = FALSE)\n",
        "pred_y_test <- predict(fit, newdata = x_test, type = \"response\")\n",
        "pred_y_test_bin = ifelse(pred_y_test > 0.1, 1, 0)\n",
        "dataout_GLM <- data.frame(pred_y_test_bin, y_test)"
      ],
      "metadata": {
        "id": "xznvWcMNUP3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colnames(x_train)"
      ],
      "metadata": {
        "id": "j5Ba-N2braF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I am having trouble in this part, Plotting \n",
        "my_data <- x_train\n",
        "my_data$y_train <- y_train\n",
        "my_data$pred_y_test_bin <- pred_y_test_bin\n",
        "\n",
        "plot_y_z_on_right_axis <- function(my_data, x, y, z) {\n",
        "# Plot y and z on right axis, with histogram of x\n",
        "# Define y and z limits\n",
        "y_lim <- c(min(my_data$y, na.rm = TRUE), max(my_data$y, na.rm = TRUE))\n",
        "z_lim <- c(min(my_data$z, na.rm = TRUE), max(my_data$z, na.rm = TRUE))\n",
        "\n",
        "ggplot(my_data, aes(x = x)) +\n",
        "  geom_histogram(alpha = 0.5, fill = \"grey\", binwidth = 0.1, stat = \"count\") +\n",
        "  geom_line(aes(y = y), color = \"blue\") +\n",
        "  geom_point(aes(y = z), color = \"red\") +\n",
        "  ggtitle(\"Y and Z Values by X\") +\n",
        "  xlab(\"X\") +\n",
        "  ylab(\"X Histogram\") +\n",
        "  scale_y_discrete(name = \"Y and Z\",\n",
        "                   limits = c(y_lim[1], y_lim[2], z_lim[1], z_lim[2]),\n",
        "                   labels = c(\"Y_min\" = y_lim[1], \"Y_max\" = y_lim[2],\n",
        "                              \"Z_min\" = z_lim[1], \"Z_max\" = z_lim[2])) + \n",
        "  theme(axis.title.y.right = element_text(color = \"blue\"),\n",
        "        axis.text.y.right = element_text(color = \"blue\"),\n",
        "        axis.title.y.left = element_text(color = \"grey20\"))\n",
        "\n",
        "}\n",
        "\n",
        "plot_y_z_on_right_axis(my_data, 'veh_count', 'y_train', 'pred_y_test_bin') "
      ],
      "metadata": {
        "id": "i0yfYCE_n-ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I don't understand this code. Need to dig deeper\n",
        "## resid.plot includes an off balance for when the model overall predicts low or high\n",
        "resid.plot <- function(data,var,actual,pred,weight,rt_text,lt_text) {\n",
        "  pr1 = paste0(paste0(pred,'*'),weight)\n",
        "  \n",
        "  header = \"Actual vs Predicted\"\n",
        "  \n",
        "  home_plot <- data %>%\n",
        "    mutate(nt = eval(parse(text = var))) %>%\n",
        "    group_by(nt) %>%\n",
        "    summarize(  act = sum(eval(parse(text = actual)))\n",
        "                , pred = sum(eval(parse(text = pr1)))\n",
        "                , exposures = sum(eval(parse(text = weight)))\n",
        "    ) %>%\n",
        "    mutate(   actual = act/exposures\n",
        "              , predicted = pred/exposures)\n",
        "  \n",
        "  home_plot <- home_plot[complete.cases(home_plot),]\n",
        "  \n",
        "  # off balance for model total prediction\n",
        "  a1 = paste0(\"data$\",actual)\n",
        "  a2 = paste0(\"data$\",pred)\n",
        "  a3 = paste0(\"data$\",weight)\n",
        "  off_balance = sum(eval(parse(text = a1)))/sum(eval(parse(text = a2)) * eval(parse(text = a3)))\n",
        "  home_plot$predicted <- home_plot$predicted*off_balance\n",
        "  \n",
        "  par(mar=c(5, 4, 2, 5) + 0.1)\n",
        "  \n",
        "  barplot(home_plot$exposures,las=2,col=\"lightblue\",ylim = c(0,max(home_plot$exposures)*1.1))\n",
        "  par(new=TRUE)\n",
        "  plot(home_plot$nt, home_plot$actual, col='darkblue',lwd= 4, axes=FALSE, ylim=c(ifelse(min(home_plot$actual)<min(home_plot$predicted),min(home_plot$actual)*0.98,min(home_plot$predicted)*0.98),ifelse(max(home_plot$actual)>max(home_plot$predicted),max(home_plot$actual)*1.02,max(home_plot$predicted)*1.02)), xlab=\"\", ylab=\"\",main=header)\n",
        "  axis(4, ylim=c(0,1),col=\"black\",las=1)\n",
        "  axis(1, xlim=c(0,1),col=\"black\",las=1)\n",
        "  mtext(rt_text,side=4,line=3.0,col=\"black\",font=7)\n",
        "  mtext(lt_text, side = 2, line=3.0,col=\"black\",font=7)\n",
        "  box()\n",
        "  mtext(var,side=1,col=\"black\",line=2.5,font=7) \n",
        "  lines(home_plot$nt,home_plot$predicted, col=\"green\",lwd=3)  \n",
        "}\n",
        "resid.plot(my_data,\"veh_count\",\"y_train\",\"pred_y_test_bin\",\"veh_count\",\"claim_count_pd\",\"veh_count\")"
      ],
      "metadata": {
        "id": "p2srfKCVwdZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0a1l-hkVGfa"
      },
      "source": [
        "#Calculate the metric for each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzvmkEk3T_2j"
      },
      "outputs": [],
      "source": [
        "library(pROC)\n",
        "\n",
        "# Define a function to compute the metrics for one model\n",
        "compute_model_metrics <- function(pred, true, var_name) {\n",
        "  tn <- sum((pred == 0) & (true == 0))\n",
        "  fp <- sum((pred == 1) & (true == 0))\n",
        "  fn <- sum((pred == 0) & (true == 1))\n",
        "  tp <- sum((pred == 1) & (true == 1))\n",
        "  total <- length(pred)\n",
        "  \n",
        "  accuracy <- (tp + tn) / total\n",
        "  precision <- tp / (tp + fp)\n",
        "  sensitivity <- tp / (tp + fn)\n",
        "  f1_score <- 2 * precision * sensitivity / (precision + sensitivity)\n",
        "  \n",
        "  roc <- roc(true, pred)\n",
        "  auc <- auc(roc)\n",
        "  gini <- (auc * 2) - 1\n",
        "  \n",
        "  # Create a data frame to store the metrics\n",
        "  metrics_df <- data.frame(var_name = var_name,\n",
        "                           accuracy = accuracy,\n",
        "                           precision = precision,\n",
        "                           sensitivity = sensitivity,\n",
        "                           f1_score = f1_score,\n",
        "                           roc_auc = auc,\n",
        "                           gini = gini,\n",
        "                           TP = tp,\n",
        "                           FP = fp,\n",
        "                           TN = tn,\n",
        "                           FN = fn,\n",
        "                           Samples = total)\n",
        "  \n",
        "  # Return the data frame\n",
        "  return(metrics_df)\n",
        "}\n",
        "# Compute the metrics for each model and combine the resulting data frames\n",
        "metrics_df <- rbind(compute_model_metrics(dataout_XGboost_simple$pred_y_test_bin, dataout_XGboost_simple$y_test, \"XGBoost\"),\n",
        "                    compute_model_metrics(dataout_GLM_top10$pred_y_test_bin, dataout_GLM_top10$y_test, \"GLM Top 10\"),\n",
        "                    compute_model_metrics(dataout_GLM$pred_y_test_bin, dataout_GLM$y_test, \"GLM\"))\n",
        "#print(metrics_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJRfhN7-dOFG"
      },
      "source": [
        "# Pretty print table of metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4w5sWQwV9Cq"
      },
      "outputs": [],
      "source": [
        "knitr::kable(metrics_df,digits = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ROC curve\n",
        "roc_curve1 <- roc(dataout_GLM_top10$y_test, dataout_GLM_top10$pred_y_test_bin)\n",
        "roc_curve2 <- roc(dataout_GLM$y_test, dataout_GLM$pred_y_test_bin)\n",
        "roc_curve3 <- roc(dataout_XGboost_simple$y_test, dataout_XGboost_simple$pred_y_test_bin)\n",
        "\n",
        "# Plot the first ROC curve in blue\n",
        "plot(roc_curve1, col = \"blue\")\n",
        "\n",
        "# Add the second ROC curve in red\n",
        "lines(roc_curve2, col = \"red\")\n",
        "lines(roc_curve3, col = \"green\")\n",
        "# Add a legend\n",
        "legend(\"bottomright\", legend = c(\"GLM_top10\", \"GLM\",\"XGboost_simple\"),\n",
        "       col = c(\"blue\", \"red\",\"green\"), lwd = 2)"
      ],
      "metadata": {
        "id": "Mo7nShIL18L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uomq2k2cdUtZ"
      },
      "source": [
        "#Plot the various metrics as plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UmIoQ_cVFLc"
      },
      "outputs": [],
      "source": [
        "options(warn=-1)\n",
        "# Melt the data frame to a long format for plotting\n",
        "metrics_df_melt <- melt(metrics_df, id.vars = \"var_name\", variable.name = \"metric\")\n",
        "\n",
        "# Plot each performance metric for each model using ggplot2 and facet_wrap()\n",
        "ggplot(metrics_df_melt, aes(x = var_name, y = value, fill = var_name)) +\n",
        "  geom_bar(stat = \"identity\", position = \"dodge\") +\n",
        "  labs(x = \"Model\", y = \"Metric Value\", fill = \"Model\") +\n",
        "  ggtitle(\"Performance Metrics for Each Model\") +\n",
        "  facet_wrap(~metric, scales = \"free_y\", nrow = 10) +\n",
        "  theme_bw() +\n",
        "  theme(plot.background = element_rect(fill = \"white\", size = 4),\n",
        "        panel.background = element_rect(fill = \"white\", size = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iz3uMoXyT2Xi"
      },
      "outputs": [],
      "source": [
        "library(dplyr)\n",
        "options(warn=-1)\n",
        "# Define the lift function\n",
        "lift <- function(depvar, predcol, groups=10) {\n",
        "  if(!require(dplyr)) {\n",
        "    install.packages(\"dplyr\")\n",
        "    library(dplyr)\n",
        "  }\n",
        "  if(is.factor(depvar)) depvar <- as.integer(as.character(depvar))\n",
        "  if(is.factor(predcol)) predcol <- as.integer(as.character(predcol))\n",
        "  helper = data.frame(cbind(depvar, predcol))\n",
        "  helper[,\"bucket\"] = ntile(-helper[,\"predcol\"], groups)\n",
        "  gaintable = helper %>% group_by(bucket)  %>%\n",
        "    summarise_at(vars(depvar), funs(total = n(),\n",
        "                                    totalresp=sum(., na.rm = TRUE))) %>%\n",
        "    mutate(Cumresp = cumsum(totalresp),\n",
        "           Gain=Cumresp/sum(totalresp)*100,\n",
        "           Cumlift=Gain/(bucket*(100/groups)))\n",
        "  return(gaintable)\n",
        "}\n",
        "\n",
        "# Example usage\n",
        "dt1 <- lift(dataout_XGboost_simple$y_test, dataout_XGboost_simple$pred_y_test_bin, groups = 10)\n",
        "dt2 <- lift(dataout_GLM_top10$y_test, dataout_GLM_top10$pred_y_test_bin, groups = 10)\n",
        "dt3 <- lift(dataout_GLM$y_test, dataout_GLM$pred_y_test_bin, groups = 10)\n",
        "\n",
        "# Plot the lift charts with different colors\n",
        "graphics::plot(dt1$bucket, dt1$Gain, type=\"l\", ylab=\"Cumulative lift\", xlab=\"Bucket\", col=\"red\",linetype = \"dashed\")\n",
        "lines(dt2$bucket, dt2$Gain, col=\"green\")\n",
        "lines(dt3$bucket, dt3$Gain, col=\"blue\",linetype = \"dashed\")\n",
        "legend(\"bottomright\", legend=c(\"XGBoost\", \"GLM_top10\", \"GLM\"), col=c(\"red\", \"green\", \"blue\"), lty=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kMjFXElRnzPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GhzFWVIX0I"
      },
      "source": [
        "#Todo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Caret cross validation\n",
        "\n",
        "* \n",
        "* "
      ],
      "metadata": {
        "id": "ONe850YyICPy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sMvKZuAvOjBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lightgbm \n"
      ],
      "metadata": {
        "id": "OksCxRBQOjYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eRyR1JnwH-fL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qhNceQmGEl_"
      },
      "source": [
        "# End"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dsxvGCJGHoD"
      },
      "source": [
        "Unused code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHS5X8-4dqNi"
      },
      "outputs": [],
      "source": [
        "#library(Hmisc)\n",
        "#hist.data.frame(gbm_data$claim_count_pd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GL2x7AYdPpwj"
      },
      "outputs": [],
      "source": [
        "#library(flextable)\n",
        "# Convert the data frame to a flextable object\n",
        "ft_metrics <- flextable(metrics_df)\n",
        "ft_metrics <- set_formatter(ft_metrics, type = \"numeric\", digits = 2) # Set the number of decimal places for numeric columns\n",
        "\n",
        "ft_metrics <- set_header_labels(ft_metrics, var_name = \"Model\", Samples = \"Total Samples\")\n",
        "ft_metrics <- autofit(ft_metrics)\n",
        "ft_metrics <- add_header_row(ft_metrics, values = \"Performance Metrics\", merge = 11)\n",
        "print(ft_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc6evR_ulhGi"
      },
      "outputs": [],
      "source": [
        "# Convert the data frame to a gt object\n",
        "gt_metrics <- gt(metrics_df)\n",
        "cols_to_format <- c(\"accuracy\", \"precision\", \"sensitivity\", \"f1_score\", \"roc_auc\", \"gini\")\n",
        "gt_metrics <- data_color(gt_metrics, columns = cols_to_format, color = \"white\", apply_to = \"text\")\n",
        "gt_metrics <- tab_style(gt_metrics, locations = cells_body(cols = cols_to_format), style = list(cell_text(weight = \"bold\", color = \"black\"), cell_fill(background.color = \"gray\")))\n",
        "gt_metrics <- gt_metrics %>% tab_header(title = \"Performance Metrics\", subtitle = \"for Each Model\")\n",
        "\n",
        "# Display the gt table\n",
        "gt_metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('h2o')\n",
        "library(h2o) # For AutoML\n",
        "h2o.init()"
      ],
      "metadata": {
        "id": "kLbQqLONOUAw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}