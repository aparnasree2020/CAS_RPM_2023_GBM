{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aparnasree2020/CAS_RPM_2023_GBM/blob/main/RPM_XGBoost_Models_AXS_1M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xiri0H-FVwo"
      },
      "source": [
        "# Welcome to CAS RPM - XGboost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Install packages\n",
        "\n",
        "* Here we will install the packages necessary to run the XGBoost part of the workshop.\n",
        "\n",
        "* The installation will take about 10 minutes\n",
        "\n",
        "* We check if the libraries are installed, if they are already installed, then we do no reinstall them."
      ],
      "metadata": {
        "id": "7boNP2TMW67g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Welcome to CAS RPM 2023 - XGboost\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azD1YGJl1WkI",
        "outputId": "328a3943-ef5a-46b5-9d33-469fa7d50ded"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Welcome to CAS RPM 2023 - XGboost\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time <- Sys.time()\n",
        "\n",
        "if (!require(xgboost)) {\n",
        "  install.packages(\"xgboost\")\n",
        "  library(xgboost)\n",
        "}\n",
        "if (!require(pROC)) {\n",
        "  install.packages(\"pROC\")\n",
        "  library(pROC)\n",
        "}\n",
        "if (!require(reshape2)) {\n",
        "  install.packages(\"reshape2\")\n",
        "  library(reshape2)\n",
        "}\n",
        "\n",
        "end_time <- Sys.time()\n",
        "elapsed_time <- difftime(end_time, start_time, units = \"secs\")\n",
        "print(paste(\"Installation of libraries took: \", round(elapsed_time/60, 2), \" minutes\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMl9EH9W4uau",
        "outputId": "6755a52f-4c9e-4e5b-e7fb-db20a71b379d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Installation of libraries took:  0  minutes\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWqpTZ-pFVNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89f6c6a-5fd0-482f-f6a3-d44b75e14c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time <- Sys.time()\n",
        "# Comment after installation so that the whole notebook can be run in one go\n",
        "install.packages('xgboost')\n",
        "install.packages('pROC')\n",
        "install.packages('reshape2')\n",
        "\n",
        "end_time <- Sys.time()\n",
        "elapsed_time <- difftime(end_time, start_time, units = \"secs\")\n",
        "print(paste(\"Installation of libraries took: \", round(elapsed_time/60, 2), \" minutes\"))\n",
        "\n",
        "#\"Installation of libraries took:  11  minutes\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY33DK77FeAP"
      },
      "source": [
        "# Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(dplyr)\n",
        "library(tidyverse)\n",
        "library(xgboost)\n",
        "library(pROC)\n",
        "library(reshape2)"
      ],
      "metadata": {
        "id": "71MIFGkQawGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Plotting functions"
      ],
      "metadata": {
        "id": "ZHjdwHxEFG-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avse.plot.classification <- function(data,var,actual,pred,weight,rt_text,lt_text) {\n",
        "  header = \"Actual vs Predicted\"\n",
        "\n",
        "  home_plot <- data %>%\n",
        "    mutate(nt = eval(parse(text = var))) %>%\n",
        "    group_by(nt) %>%\n",
        "    summarize(  act = sum(eval(parse(text = actual)))\n",
        "                , pred = sum(eval(parse(text = pred)))\n",
        "                , exposures = sum(eval(parse(text = weight)))\n",
        "    ) %>%\n",
        "    mutate(   actual = act/exposures\n",
        "              , predicted = pred/exposures)\n",
        "  \n",
        "  home_plot <- home_plot[complete.cases(home_plot),]\n",
        "  \n",
        "  # off balance for model total prediction\n",
        "  a1 = paste0(\"data$\",actual)\n",
        "  a2 = paste0(\"data$\",pred)\n",
        "  off_balance = sum(eval(parse(text = a1)))/sum(eval(parse(text = a2)))\n",
        "  home_plot$predicted <- home_plot$predicted*off_balance\n",
        "  \n",
        "  par(mar=c(5, 4, 2, 5) + 0.1)\n",
        "  \n",
        "  barplot(home_plot$exposures,las=2,col=\"lightblue\",ylim = c(0,max(home_plot$exposures)*1.1))\n",
        "  par(new=TRUE)\n",
        "  plot(home_plot$nt, home_plot$actual, col='darkblue',lwd= 4, axes=FALSE, ylim=c(ifelse(min(home_plot$actual)<min(home_plot$predicted),min(home_plot$actual)*0.98,min(home_plot$predicted)*0.98),ifelse(max(home_plot$actual)>max(home_plot$predicted),max(home_plot$actual)*1.02,max(home_plot$predicted)*1.02)), xlab=\"\", ylab=\"\",main=header)\n",
        "  axis(4, ylim=c(0,1),col=\"black\",las=1)\n",
        "  axis(1, xlim=c(0,1),col=\"black\",las=1)\n",
        "  mtext(rt_text,side=4,line=3.0,col=\"black\",font=7)\n",
        "  mtext(lt_text, side = 2, line=3.0,col=\"black\",font=7)\n",
        "  box()\n",
        "  mtext(var,side=1,col=\"black\",line=2.5,font=7) \n",
        "  lines(home_plot$nt,home_plot$predicted, col=\"green\",lwd=3)  \n",
        "}"
      ],
      "metadata": {
        "id": "9-Vhx-bdKj3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmtw_z4vFi5_"
      },
      "source": [
        "# Load CSV datafile \n",
        "## *  Data split as train and test (80/20 split) \n",
        "\n",
        "*   Train data - Used for model training\n",
        "*   Test data - Hold out data used for evaluating model performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path <- \"https://raw.github.com/aparnasree2020/sampledata_casws/master/gbm_data_rpm_2023_1M_v3.zip\"\n",
        "temp <- tempfile()\n",
        "download.file(path, temp)\n",
        "unzip(temp, \"gbm_data_rpm_2023_1M_v3.csv\")\n",
        "gbm_data <- read.csv(\"gbm_data_rpm_2023_1M_v3.csv\")\n",
        "unlink(temp)\n",
        "full_data = gbm_data\n"
      ],
      "metadata": {
        "id": "-HaTPOloOXz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(031311)\n",
        "sample <- sample(c(TRUE, FALSE), nrow(full_data), replace=TRUE, prob=c(0.8,0.2))\n",
        "train_data  <- full_data[sample, ]\n",
        "test_data   <- full_data[!sample, ]\n",
        "\n",
        "x_train <- train_data[,!names(train_data) %in% \"claim_count_pd\"]\n",
        "y_train <- train_data[,names(train_data) %in% \"claim_count_pd\"]\n",
        "\n",
        "x_test <- test_data[,!names(test_data) %in% \"claim_count_pd\"]\n",
        "y_test <- test_data[,names(test_data) %in% \"claim_count_pd\"]"
      ],
      "metadata": {
        "id": "izzLpFgjiSwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrow(x_train)\n",
        "ncol(x_train)\n",
        "nrow(x_test)\n",
        "ncol(x_test)\n"
      ],
      "metadata": {
        "id": "XtPYccQouYFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you want to look at the data a bit before we get into the modeling."
      ],
      "metadata": {
        "id": "Is6qNRp3NhEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colnames(train_data)"
      ],
      "metadata": {
        "id": "ooaA1eyQN1GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data$nt <- ntile(train_data$LOO, 10)\n",
        "avse.plot.classification(var=\"driver_age\",data=train_data,actual=\"claim_count_pd\",pred=\"claim_count_pd\",weight=\"ee_pd\",lt_text=\"exposures\",rt_text=\"freq\")"
      ],
      "metadata": {
        "id": "Atx4vWQnNgP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit a standard GLM "
      ],
      "metadata": {
        "id": "UAqo0p1-T_3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a place to collect predictions (and a classification from each model)\n",
        "df_train_pred <- data.frame(y_train)\n",
        "df_test_pred <- data.frame(y_test)\n",
        "df_train_pred_bin <- data.frame(y_train)\n",
        "df_test_pred_bin <- data.frame(y_test)"
      ],
      "metadata": {
        "id": "rVRv-aN1UU8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a GLM\n",
        "fit <- step(glm(y_train ~ ., data = x_train, family = \"binomial\"), direction = \"both\", trace = FALSE)\n",
        "df_train_pred$pred_y_GLM_init <- predict(fit, newdata = x_train, type = \"response\")\n",
        "df_test_pred$pred_y_GLM_init <- predict(fit, newdata = x_test, type = \"response\")\n",
        "df_train_pred_bin$pred_y_GLM_init <- ifelse(df_train_pred$pred_y_GLM_init > 0.1, 1, 0)\n",
        "df_test_pred_bin$pred_y_GLM_init <- ifelse(df_test_pred$pred_y_GLM_init > 0.1, 1, 0)"
      ],
      "metadata": {
        "id": "6hvQ0-RwT7sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tmp.train <- data.frame(x_train, df_train_pred)\n",
        "df.tmp.test <- data.frame(x_test, df_test_pred)"
      ],
      "metadata": {
        "id": "LVCzOce7de_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's build prediction bands for lift table review\n",
        "df.tmp.train <- df.tmp.train %>%\n",
        "  mutate(freq_nt = ntile(pred_y_GLM_init/ee_pd,10))\n",
        "df.tmp.test <- df.tmp.test %>%\n",
        "  mutate(freq_nt = ntile(pred_y_GLM_init/ee_pd,10))"
      ],
      "metadata": {
        "id": "-xYD8j5JP_V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of variables to make the function call below easier\n",
        "colnames(df.tmp.train)"
      ],
      "metadata": {
        "id": "9iTKRwrHLQLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in case you need to bin for viewing - we'll use a single column repeatedly for this purpose rather than bloating the file\n",
        "var.group = \"est_current_odo\"\n",
        "df.tmp.train <- df.tmp.train %>%\n",
        "  mutate(nt = ntile(eval(parse(text = var.group)), 10))\n",
        "df.tmp.test <- df.tmp.test %>%\n",
        "  mutate(nt = ntile(eval(parse(text = var.group)), 10))"
      ],
      "metadata": {
        "id": "5zDC_GOkNSj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var.curr = \"freq_nt\"\n",
        "avse.plot.classification(var=var.curr,data=df.tmp.train,actual=\"y_train\",pred=\"pred_y_GLM_init\",weight=\"ee_pd\",lt_text=\"exposures\",rt_text=\"freq\")\n",
        "avse.plot.classification(var=var.curr,data=df.tmp.test,actual=\"y_test\",pred=\"pred_y_GLM_init\",weight=\"ee_pd\",lt_text=\"exposures\",rt_text=\"freq\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VwxZx3RPvRo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FoeSDqRVNXJ"
      },
      "source": [
        "#XGboost with essential hyperparameters \n",
        "\n",
        "All features are used for this fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx9D2hAqIqr_"
      },
      "outputs": [],
      "source": [
        "print(colnames(x_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert data to XGB format"
      ],
      "metadata": {
        "id": "OvyIEUWPKKV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain <- xgb.DMatrix(data = as.matrix(x_train)\n",
        "                        , label = y_train\n",
        "  )\n",
        "dtest <- xgb.DMatrix(data = as.matrix(x_test)\n",
        "                       , label = y_test\n",
        "  )"
      ],
      "metadata": {
        "id": "U18zbPH67_54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zUVdj03q252G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Explanation of Weights\n",
        "\n",
        "*   The XGboost has a feature \"scale_pos_weight\" which is a hyperparameter in XGBoost that adjusts the weight of positive samples relative to negative samples in imbalanced datasets. It is defined as the ratio of the number of negative samples to the number of positive samples and is used to help the model learn more from the minority class.\n",
        "\n",
        "*    This is an important hyper parameter, especially for classification task with unbalanced dataset. \n",
        "---\n",
        "\n",
        "## Explanation of AUC \n",
        "* XGboost has another feature \"eval_metric = \"auc\", AUC stands for Area Under the Curve and is a measure of the performance of a binary classifier. It represents the degree or measure of separability between the true positive rate (TPR) and the false positive rate (FPR). AUC ranges from 0 to 1, where an AUC of 1 indicates perfect classification performance, and an AUC of 0.5 indicates a random classification. AUC is commonly used to compare the performance of different models, and it is considered a more reliable measure than accuracy in imbalanced datasets.\n",
        "\n",
        "---\n",
        "## Explanation of eta ( also known as learning rate)  \n",
        "The learning rate controls the magnitude of the updates to the model weights during training. A smaller learning rate means that the model makes smaller updates to the weights at each iteration, which can result in slower convergence but can also help prevent overfitting. On the other hand, a larger learning rate can lead to faster convergence but may also result in overfitting or instability.\n",
        "* The learning rate is also multiplied by a shrinkage factor (denoted by the parameter lambda or alpha) to further control the magnitude of the updates. The idea is to have a larger learning rate in the beginning of the optimization. As you get closer to the global minima, the idea is to reduce the learning rate. \n",
        "\n",
        "![Capture.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/4RDKRXhpZgAATU0AKgAAAAgABAE7AAIAAAACTQAAAIdpAAQAAAABAAAISpydAAEAAAAETQAAAOocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFkAMAAgAAABQAABCYkAQAAgAAABQAABCskpEAAgAAAAM3MAAAkpIAAgAAAAM3MAAA6hwABwAACAwAAAiMAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMjAyMzowMzowOSAxMToyMTowNQAyMDIzOjAzOjA5IDExOjIxOjA1AAAA/+ELFGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjMtMDMtMDlUMTE6MjE6MDUuNjk4PC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPk08L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgBPwJlAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKp6tqMWkaPd6hcf6u1haUjPXAzj8elAHDSeN9vxoTSPN/wBC8j7GRnjzj8+frnCV6LXyybfW7jWvt4gmN9KDqKkD5iNxbzAOvYn6c19L6FqseuaBZanDgLcwq5AP3Wxyv4HI/CgC/RRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUVmWPiPRtSnaCx1S1mmVirRLKN4IOPu9aANOiiigAooooAKKKKACiiigAooooAKKR3WNGeRgqqMszHAA9awZdY1C+50eOCG3/AIbm6Vn8weqxgg49CSM+mKmUlHVjSb2N+iuaLa+f+Ytaj/tx/wDtlG7X/wDoLWv/AIA//Z1HtYdy/ZyOlormt2v/APQWtf8AwB/+zo3a/wD9Ba1/8Af/ALOj2sO4ezkdLRXNbtf/AOgta/8AgD/9nRu1/wD6C1r/AOAP/wBnR7WHcPZyOlormt2v/wDQWtf/AAB/+zo3a/8A9Ba1/wDAH/7Oj2sO4ezkdLRXNbtf/wCgta/+AP8A9nRu1/vq1r/4A/8A2dHtYdw9nI6Wiua3a/8A9Ba1/wDAH/7Ojdr/AP0FrX/wB/8As6Paw7h7OR0tFc1u1/8A6C1r/wCAP/2dG7X/APoLWv8A4A//AGdHtYdw9nI6Wiua3a//ANBa1/8AAH/7Ojdr/wD0FrX/AMAf/s6Paw7h7OR0tFc4s2vxfML6xn/2HtGTP/Ag5x+RrR0zVxeyNbXMJtb1F3NCW3Bl6bkbjcueOgIyMgZGajOMtiXCS3NKiiirJCiiigAqnqemW2r2gtb5fMt/MV3iP3ZNpyAfUZAOO+PSrlFAHm9wAn7QVmFGAdOPH/AWrvtP0220uKSKyTyoXkaURD7qFuTtHYE5OPUmuCu+P2g7HPfTjj/vl69HoAKKKKACsXVvGHh/Q2ZNT1a2hlX70QbfIP8AgK5P6VtV8+fGGw+x/ECWYDAvII5vxxsP/oFAHvGl6na6xpcGoWDmS3nXdGxGMjp0q3XA/Bq/+1+Axbk82dzJEB7HD/zY131ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBR1y/8A7K8P39/nBtreSUe5Ckj9a+XNKsn1XW7OyBJa6uEiz3+ZgM/rXvnxav8A7F8PLtAcNdSRwL+Lbj+imvKfhTYfbviJYkjKWyvO34KQP/HiKAPopEWNFRBhVGAPQUtFFABRRRQAUUUUAFFFFABRRRQBheIpPtFzYaWf9Xcs00w/vxx4O36FmTI7jI71JUGsE/8ACXaWM8Gxuzj/ALaW9T1x1n7x1UvhCiiisTUKKKKACiiigAooooAKKKKACiiigAooooAKKKKACs/Wt0Ontfw8T2H+kxn12jLL9GXKn61oVT1jjQ7/AB/z7Sf+gmnF2Ynqjo0dZI1dDlWAIPtTqrab/wAgq0/64J/6CKs16JwhRRRQAUUUUAecXv8AycHp/wD2Dj/6DJXo9ecahx+0HpeO+nNn/vmWvR6ACiiigAryD462XzaPfKO0kLn/AL5K/wDs1ev15/8AGez+0+AxOBza3UchPsQV/mwoA574FXuJNYsWPURzIPpuDfzWvYa+f/g3efZvHywk/wDH1bSRY9SMP/7JX0BQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeS/HW/22ekaep+/JJOw9MAKP8A0JqpfAux36nq1+R/qoUhU/7xLH/0AVkfGW/+1ePPs4PFnbRxke5y/wDJhXd/Baw+zeCZLlh813dOwPqqgKP1DUAeh0UUUAFFFFABRRRQAUUUUAFFFFAHPax/yN+l/wDXjd/+jLerFV9Y/wCRv0v/AK8bv/0Zb1YrirfGdVL4QooorI1CimSyLDC8shwiKWY+wqjoGuWniTQbTV9N8z7Ldpvi8xdrEZI5HbpQBo0UVl694gsvDljDdaiZNk9zFaxiNdxMkjbVH0yetAGpRVC1u9Ql1nULa60z7PZQCI2t59oV/tRYEuNg5TaQBz1zx0q/QAUUUUAFFFFABRVDVbvULRbQ6Zpn9oGW6jinH2hYvIhJ+eXn720c7Rye1X6ACisy+8QWWn+INK0a48z7XqomNuFXK4iUM5J7cEfnWnQAVS1j/kBX/wD17Sf+gmrtUtY/5AV//wBe0n/oJoW4nsbum/8AIJtP+uCf+girNVtN/wCQTaf9cE/9BFWa9I4QooooAKKKKAPONS4/aD0j/a05v/QZa9HrzjVP+Tg9G/7Bzf8AoM1ej0AFFFFABXO+P7T7d8P9ZixnbbGXH+5h/wD2WuiqC9tlvdPuLV/uzxNGfoRj+tAHzT4Du/sPj7Rps4BuljJ9n+T/ANmr6dr5It5ZLHUIpQMSW8obHoVOf6V9axyLLEkkZyrqGU+oNADqKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKo63fjS9Bv78nH2a3eUZ9QpI/WgD5p8Yah/anjPVrsHcr3ThD6qDtX9AK+hvA9h/ZngbSLYjawtldh6M/zn9WNfNWl2b6prNpZKSXup0iz7swH9a+skVY0VEGFUYAHYUALRRRQAUUUUAFFFFABRRRQAUUUUAc9rH/I36X/143f/AKMt6sVX1g/8VdpY/wCnG7/9GW9WK4q3xnVS+EK5X4kWE+q+CbiwtNSt9PmuJYkQ3M5hS4+cHyS45G8Dbxyc4rqqpavo+n6/pc2naxaR3dnMBvikHBwcg+xBGcis07O5o9UeSaDpOk2Gt6hoGr+Ernw7Pqeky/6BFfLc2F2sZBMmB8yuO2ccZ7nnO8O6d4cg+GHgzT7jS9SvrrWWkuf7L02RY11B0UhmmLMo2qCpxuHOODzXrOgeBvDnhi6ludF04RXEsflNNLNJNJs67Q0jMQvA4HHFUD8KvBh0xLD+xsW8c5uIgLqYNC5GDsbfuQHA+VSBwOK050Rys8xtIn0qT4jaRb6OdAtP+EXkuDpQvBcLHIY5Bv8AlJCkg8gH0PpU3iPwJ4ct/hj4V1Aaasl7f3emi6uZXZ3m8zG/JJ77iOO2B2FeoWfw48KafHeJZaSsIvrN7G62zyZnhYksGO7JY7j85+bHGcVoX/hbRtU8NR6BfWQl0yNI0SHzHBUJjZhgdwIwOc5o59dA5NDyHxRZ2+nwfFmysolhtrbS9KihjXoiLEwUD6ACtnUvDWneFfE3gbVdFWaHUNQv1t765ad3e7V4mLeZk/MSRn27Y4ruj4C8Nmy1G0bT2aHU7eC1uw1zKTLHCu2MElsjA7ggnuTWje6Bpmoyac95beY2mTCe0PmMPKcKVB4PPBPByKXOHKeSWHhzR/FHgDxJ4s8RyyjXlmvvMuzcOj6eYmYJEvOFAULxjndg5r0v4ff8kz8Mf9gi0/8ARK1554l8E6rq2o6wH8AWFzqF88iQ6vBqflWxU5CSywFsmRQcn5TlhkGvVPD+l/2H4Z0zSRJ5v2CzitvMxjfsQLn8cUSegRWp4tonhHw/e/CHWPEV5cSnVbGS/kt7tbl0bT3jlkZEjwcLk4YjHO/6Vr+HLCD4i+KpYvHyteNZaJp01vp0rMke6aLdNLsBG5t/y57cD0rT8FfCbSU0cTeLdCjOpi9nlKtOWSRfOZoy6I2x+CPvAkdK7HxB4I8PeKJ4Z9a04TXEClI54pXhkVf7u+NlYr14zjk03JXEoux5M0rxWVppMN1Ld6dpXxBs7WxklcuUjBDGPefvBSxA7iruneDdF8R2PxC1DWbeS5ntNavltSZnC25WNXDoAQA2Tye+AO1enJ4M8PR6Vp+mw6XFFZ6bdR3lrFEzII5kOVfggscnJznPfNWbTw5pVjb6nBa2vlxarPJcXi+Yx82SRQrtyeMgDgYA7UufsPl7nkFno9h4j1/4UX2uWqXt1faVcG5mmJLTGKGNoyx7kEk59TXuVc7ceA/Dd1p+k2U2nnydGx9g2XEqtAMAYDBgxGAMgk5xzXRVMpXKirBVLWP+QFf/APXtJ/6Cau02SNJY2jlUOjgqykZBB6ipKNLTf+QTaf8AXBP/AEEVZrmbdtS0dFSzY39mgwLad8SoPRJD976Pz/tCtjTtZs9TLRwSFLiMZktpRslj9yp5x7jg9ia74zUtjilFx3L1FFFWSFFFFAHnGr/8nB6F/wBg9v8A0GevR6841nj9oPw/jvpz5/75nr0egAooooAKKKKAPlrxdZ/YPGWr2wGFS7k2j/ZLEj9CK+i/Bt59v8E6PcZyWtI1Y+rKu0/qDXiXxds/snxEupMYF1FHMP8Avnaf1U16d8H737V8PYIs5NrPJCfz3/8As9AHc0UUUAFFFFABRRWB4huGnvLfSVYrFNG8tzg4LRjChP8AgRbn2UjvSbsriehNN4r0mORo4pZroqcMbS2kmUEdRuRSufbOaZ/wl2n/APPDUv8AwXTf/E1CqhFCoAqqMAAYAFLWXtGRzkv/AAl2n/8APDUv/BdN/wDE0Hxbp4/5Yaj/AOC+b/4moqKPaMXOyX/hLtP/AOeGpf8Agum/+Jo/4S7T/wDnhqX/AILpv/iaioo9ow52S/8ACXaf/wA8NS/8F03/AMTR/wAJdp//ADw1L/wXTf8AxNRUUe0Yc7Jf+Et085/cajx/1D5v/iaP+Eu0/wD54al/4Lpv/iaioo9ow52S/wDCXaf/AM8NS/8ABdN/8TR/wl2n/wDPDUv/AAXTf/E1FRR7Rhzsl/4S7T/+eGpf+C6b/wCJo/4S7T/+eGpf+C6b/wCJqKij2jDnZL/wl2n/APPDUv8AwXTf/E0f8Jdp/wDzw1L/AMF03/xNRUUe0Yc7Jf8AhLtP/wCeGpf+C6b/AOJo/wCEu0//AJ4al/4Lpv8A4moqKPaMOdkv/CXaf/zw1L/wXTf/ABNH/CXaf/zw1L/wXTf/ABNRUUe0Yc7LEfivSXdVllntdxwGuraSFSf95lA/WtmudZQylWAIIwQR1p2gTm1v5tJJzCkQmtR/cTO1kHsDgj0DYHAFVGd3YqMrnQUUUVoWFcR8XdR+w/D64iBw95KkA/Pcf0Uj8a7evG/jnqe670vS1P3Ea4ceuTtX/wBBb86AOY+FOnf2h8QrJmGUtVe4b8Bgf+PMtfRdeQfAvTf+Qrqjr/ct4z/483/slev0AFFFFABRRRQAUUUUAFFFFABRRRQBz2sf8jfpf/Xjd/8Aoy3qxUGsDHizS3OcfY7pc47l4D/7KanrirfGdVL4QooorI1CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooqG7uVs7Ge5kBZYY2kYL1IAzx+VAE1V7uwt75U+0Jl4zmORWKvGfVWHKn6VV/tpLdFOrWtxpuQDvuFzF/38XKj8SD7VoRyJLGrxOrowyGU5B/Gm04vUlNSIItQ1TTOLlW1S1H/AC0QBbhB7rwr/UbT7Ma2bHUbTU4TLYzrKqnDDkMh9GU8qfYgGs+qlzp0VxMLiNpLa6UYW5gba4HoezD2YEe1bxrNaSM5Uk9jpKK5+LWr3T/l1iH7RCP+Xy1Q5H+/HyR9VyPZRW3bXMF5bpcWk0c8LjKyRsGVvoRXSpKSujnaa3PPdb4/aC8PE9P7Pcf+Oz16PXnGu/8AJfvDv/Xg38p69HpiCiiigAooooA8Y+Olls1PSb4D/WQvCT/ukEf+hmr3wKvd1lq9iT9ySOZR67gQf/QRWn8a7L7R4Mt7pR81rdqSfRWUg/rtrivgtffZvHElsT8t1auoHqykMP0DUAe90UUUAFFFFABXM6of+KxQdvsH/tSumrmdU/5HJP8Arw/9qVM/hJlsS0UUVzmIVxGh+KruzPjWPxFcee2gXck6HYqEWjRCWNeAMkAMMnk129eQfEu0uE8eQaVbIwg8ZW0FjOy9jDOrOx/7YyMPwprUaNb4e+MNZbQdb/4Te4We/wBMgi1BnESxYt5bcShcAAfKQ6k+oq7oXju30bwLoN1481YDVdUg+0KiW5aR1YllAjiUnCqVGcduea574rWVxbeJrOLTlKjxTYjQn2DCofPjYMf+2bzD6CovFYuvC/xSk1J9ch8OafcaXFa2d7Pppu4gEY7ochh5Z6NzwfwqrJlWTO/udUm8S+H7G+8EamjpNdwlrhFRl8kOPNVg/IO3IwBuBwOOSOK1bxrr9tpXiqaC/wBsmn+IoLK2Pkxny4WaMMvK853Hk5PPWtf4TQlrPXNRS/nvoNQ1FplmfTvsccrbQGkiTexKtgfMcZIPFcXrv/ID8cf9jba/+hQ0Ja2BbnucsscMLyzOsccalndzgKByST2FcnafFPwZe3kFrba2jzXE6QQKYJQJnZwgCErhhuIGRkDuRVn4i6df6v8ADjXLHSQzXc1o6xovWTuUHuQCPxrz/wAQeNPDHiCz8FWGiKz3MGu6d+48h1NjhwCjEgBT/Djv1HAzSSuJK56BrXxD8LeH9UbTtW1ZYrpFDyRpDJL5SnoXKKQnr82OOazNe+Jen6N4y8P6OrrNbapFJNLcRwySbU2gxFCgIbcTyRnAHOMg1wRv7zwp4j8V2ureKrfw+19qc91HBd6Ibv7ZC/3Ckm8bht+XZ2IPrVnS1h8KzfC6bVZ7qKzhj1GLz7628h0MoUxIyBn2kjgDceB26B8qHZHpHj7xYvgvwbeax5YlmjG2CNlYq8h6BioOBweTge/Nct/wtGzi8bWEl5qhg0G70FrlYmtHDPci4EfyqU80nAcbRwQM471v/FWCW4+FPiGOBGkf7GzbVGTgEE/oDXPeH9Q0/XPjBpOoadNHd258Jv5UyjgMt0qNjPQg7h+dJWsJWsdpY+MvD2o+G5tftNVgbS4NwmuGygiI6hgwBU8jgjPI9RUXh/xz4c8UXT22iakJ50jEpikhkicof41DqCy+4yOa8o1vTr2+0vxl/ZysY7TxdFdXSpB537lUQu3lZHmYOGK5GcVqaHfnxP8AEnw/cxeLv+Ehk08TSM9jofkJAjRlSsshk+XdxhcE5HQdafKgsd5pXxG8Ka15p03V0ljhtzcyymGRI44xjJZ2UKCMjIJyM9Kk0Lx/4Y8S3/2LRtUWa5KGRI3hkiMijqyb1G8e65rzOw0q91T9lGytdJhaWXaJXhiTc0iLdFnAXjccAnGecY71JZakfFPjLw1HD4yGuy2N59oEdh4f8g2yBSHErtIPLRgdpGCSccGjlQWR7XRRRUEhUOnk/wDCaRDt/Z8vH/bSOpqg0/8A5HWH/sHy/wDoyOqh8RUdzqKKKK6DYK+afiLq39sePdSmVt0cMn2eP0wnynH1IJ/GvoXxDqq6J4dv9ScgfZoGdc92x8o/E4H418v6XYy6zrlrZISZbudY93U5ZsE/rmgD6D+F+lf2V8P7AMu2S6BuX99/3f8Ax0LXXUyGFLe3jhhXbHGoRFHYAYAp9ABRRRQAUUUUAFFFFABRRRQAUUUUAZmuafLeQQz2gBu7OTzYlJx5gwQyZ91Jx6HB7VTtbqK7i3xE5U7XRhhkYdVYdiK36z7/AEOw1Gbzp4mSfGPPgkaKTA6AspBI9jkVlUp8+ppCfKVqKYfC0PbUtTHt9qP+FH/CKw/9BPVP/An/AOtWPsJdzX2yH0Uz/hFYf+gnqn/gT/8AWo/4RWH/AKCeqf8AgT/9aj2Eu4e2Q+imf8IrD/0E9U/8Cf8A61H/AAisP/QT1T/wJ/8ArUewl3D2yH0Uz/hFYf8AoJ6p/wCBP/1qP+EVh/6Ceqf+BP8A9aj2Eu4e2Q+imf8ACKw/9BPVP/An/wCtR/wi0P8A0E9T/wDAn/61HsJdw9sh9FM/4RWH/oJ6p/4E/wD1qP8AhFYf+gnqn/gT/wDWo9hLuHtkPopn/CKw/wDQT1T/AMCf/rUf8IrD/wBBPVP/AAJ/+tR7CXcPbIfRTP8AhFYf+gnqn/gT/wDWo/4RWH/oJ6p/4E//AFqPYS7h7ZD6oTRDW5zpsB326uPtsg5VVBz5We7N0I7KSTjK5ur4WszxcXWoXC90ku3AP12kZrWtraCzt0t7SGOCGMYSONQqqPYCrhRs7smVW6siXr1rHn8Mac8jS2ayadOxyZLJvLyfUr9xj/vKa2KK6NzDY5ySx1yx5Q2+qRDt/qJgP1Rj/wB8CoV1q1SVYb4SafOxwI7xPL3H0Vvut/wEmuppksUc8TRTxrJGwwyOuQR7g1jKjF7GqqyRk1SfTRHcNdabM1jdOcu8Q+WU/wC2nRvr970Iq1J4WtYudInn0w9kgbMX08tsqB/ugH3qtJHrdj/r7SLUYh/y0s22P+MbnH5OT7Vl7KcXeJp7SMtGcrqS6kvxS0PXNXt4oLK1gaCa8ifMQ+WTDNnlB84HPA9TXpysrqGQhlYZBByCK5m31ixubj7MJvKucZNtOpilx/uNgke/SkSwm09zJok4tMnLWzLugf8A4D/CfdSPUg1ca1tJEyp9YnUUVj2niKIzJbarCdPuWO1d7bopD/sScA/QhW9q2K3TT1Ri01uFFFFMRznxBsf7R+H+sQ4yVtzMPqhD/wDsteCeBL7+zvHmj3BO0faVjY+gf5D+jV9NXECXNtLBKMpKhRh6gjBr5Nmjm03UpIids1tMVz6Mp/xFAH1tRVfT7tNQ021vI/uXEKSr9GAP9asUAFFFFABXM6p/yOSf9eH/ALUrpq5nVD/xWKD/AKcP/alTP4SZbEtFFFc5iFFFFABRRXN+KPFsmh3+n6VpWmPq+sajvMFoswiUIgy7u5BCqMjscngUAdJRXl3izxvqt54B8U2Q0Z9N1zT7Yi7gN6P3UEiNieKQL+8HGMYBzwcVy0Hh6d/FXhfQ7jwPZw6d9mmujYjVy8cjZiVrhvk5ZVx8p656jFVylWPcNSsv7R0u5shc3FqbiJoxPbSbJIsjG5W7EdRXJQeBdYu9R0yXxV4qfWLTS51ube2WxSAtMgwjyMGO4jOeAOeayvDvjWx0v4f6BH4a8OSG61a5uotP0eO73cpNIZHaZxwvBYnBxuAAxTvE3iiSfwvdxeM/Bs8LW17aAQfbCYJt8qhXSdFGSp5K4Hb1oswsz0qiuN1Hxtqb+Ib7SfCfhttbfTAovZnvUtkjdhuEakg72x16AdzVSf4oJLb+Hn0TRLnUZtca4iS2MqxSQSwj5kcEYGDnJzwBnnpSsxWZ3tFebar4/wBbl8L+LrUaGdL1/RrIzNGL1ZEWN0YiZJAvJUKTtIGSAM88ZGl6jrF54s8DXuoWK/2gdBu2jjN3v+0/u4yrM+35S/U8HGe9HKFj2CiuL/4WJFL8PtM8RWen+ddalPFawaeZ9pNw8mxo9+3+Ehznb0XoK7SlYQUUUUAFFFFABUGn/wDI6w/9g+X/ANGR1PUOnn/itIh/1D5f/RkdVD4io7nT0UUV0Gx5h8bda+zaDaaRE2HvJfMkAP8AAnQH6sQf+A1yvwY0X7f4uk1GRcxafEWB/wCmj5Vf03H8BWH8Rdf/AOEh8a3k8bbre3P2eDngqpPP4tuP416/8J9COjeCIZpV2z6g32lsjkKRhB/3yM/8CoA7aiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDzPxbawXnxs8OW93Ck0MlowaORQVb/W9jXXyeGnt+dH1Ge19IZ/9Ii/JjuH0DAe1cr4m/5Lh4Y/692/9qV6PSaT3Gm1sctc/wBoQQvFq+k/ardhh5LP9+pH+1GQG/ABqg069aHd/wAI9qEd1FH9/T7mQny/YE/PGfZgR6AV2FUr/SNP1Tab+0jmdPuSEYdP91hyv4Gs/Z21i7F899JEOn67a304tpA9pe4J+zTgK5A6lT0ce6k474rTrmr7wrM8Bjtb0XMOdwt9RTzQCOhWQYdSP7x3EVRXVde8O8ajp9zd2a9Sr+eVH+zKACR/10VfdqtN9SWl0Ozr5r+JOn/2b8QtUQDCzSCdT67wGP6k19BaN4h0zXoDJpd2kxX78ecOn1Xrj36HsTXlPxy0wpqumami8TRNA5A7qcj89x/KqJO6+F+o/wBo/DzTiTl7cNbt7bScf+O7a66vJfgZqX+i6ppchxtdbmMHuCNrH9F/OvWqACiiigArmdU/5HJP+vD/ANqV01c9r8RttWtNRb/UNG1tM3ZCSCjH0GQR9WWplsTLYKKKK5zEKKKKACvPPiJ4KuNa17S9dtdNOsCzhkt59PW+azeRGIIdJFZeQRyCcEGvQ6KE7D2PIrbwFqLeGPFrW3hiLSbnUtPNpZWr6nJdXEnBz5kjyGMDOMAdOcmuxOi6gfH2gaj9n/0Sz0me3nk3r8kjGIquM5P3W5AxxXWUU7sLnkujeDPEuieF/COoW+nxzav4fnvvN017hF86K4kfO2QEqGC7WGTjqD6Va8R6V448W6HfNeacllG11Zmz0kTxO6LHKGlleQYGSOihjwvr19Qoo5gueR658P7m18YaxqK+GJvElrqkouI2ttZexe3faAyOu9VZSRkMORnHNXND8DappWq+CJhpdrapYXF/caglpcPIkBmiKpzK5dyTgEjIznoK9Qoo5mF2efap4T1a/wDEXjmWOBUt9Z0RLK0maRcPJ5cikEZyMFhyRVbw/ofiF/EXg291LRXsI9I0ueyud1zFJhtkaqRtY5DbT06d69KpGUOpVhkMMEUXC55Xofh+b/hc+o2Csr6NpE76vGgOdlzdIFCEdBjEzj03ivRNEvdSvrF5dZ0r+yp1mdFg+0rNuQH5X3LwMjnHUUzQfDWk+GbSS20S0FtHNIZZCZGkZ2xjLM5LHgDqa1KG7g2FFFFIQUUUUAFQaf8A8jrD/wBg+X/0ZHU9GhxG51u5v1z5EMX2aNuztuy+PUDCj6hh2q4blR3OhrmPiF4jHhrwfdXEb7bqceRbYPO9h978Bk/gK6evnn4qeKB4g8Vtb2z7rLT8wxkHhn/jb8xj6KPWtzYwPCmhv4j8UWOmKDslkBlI/hjHLH8gfxxX1GiLFGscahUUBVUDAAHavMvgv4Z+xaRNr1ymJrz93BkfdiB5P4sP/HR616fQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeXXes2fh342eKNY1NzHaWXhmCaUgZOBK5wB3J6Aepq7F8TdWtP7NvfE/g6fR9E1OZIYb43ySvCZDiMzRADywcjnJxnBqr4p8Aan4n8YeK8qLew1bw9FY292XUgTrIzYKg7sD5cnHTpzUOqWXjzxtpeneG9c8OQaRbx3UEupaoL+OVJlhdXxCi/MCxUEbgMdOaALsnxQ1e4vNWfQPBlxq+maRevZ3MsF8gui6NtcpbbSzAHOMkE46Ve1n4galF4tuPD3hbw1/bN5Z2sdzdCfUEs9ofJVUDKS7YBz0A4BNcZ4u8E69rWranIngG0XWpJHFh4m0vVvsYjB4SSVA29nUYyMNnHGK0/GHhPVtSvbWLXPA9n4xigsoY4dStb5bK8jmUfPvZmXKlvmG3pk8HNAHpOgapJregWeozafdabJcR7ntLyPZLC3Qqw+o/EYNaFcz8PNI1nQvAthp/iW7a61CPeXLTGUxqXJSPeeW2qQM+3pXTUAeceKOPjb4XI6+Qw/wDQ69HrzjxVx8avCxPTyW/9nr0egAooooAKKKKAMu/8N6VqNyt1NaLHdqcrdQMYpVP++uCfociqjqmo+Ibv7XGsi6eyRwI65CsyBy49zuC57bTjqc79Zt/p0zXBvNNeNLkqEkSUHZKo6ZxyCMnBGepBB4xnVi5RsiotJ6mfrirbadPqkShbuxheaORR8xCjJQ+qtjBH49QKsDxGxH/IE1f/AMBx/wDFV5B4t+J2q3nm6VFZR6f5Uuy4G/zGYo3K5wMDI545/Ovb9Mv4tU0m1v7f/V3MKyr7BhnFZ0oTjGzZsqlNPWN/wOW8LfEWPxBbmW80a/01AyoJ3jLwszSLGqh8D5izDjHHc12dY3ir/kCxf9f9l/6VRVs10xg40k5O7u/0JxFWlUrN0Ycke12/xYU2SNJonimRZI3UqyMMhgeoI7inUUjEwZPCwVj9g1W+tI+0QKSqPpvUsPpnA9KZ/wAIzd/9DBef9+Yf/iK6GilyoVkc9/wjN3/0MF5/35h/+IqrAZ7a+uNOvZPNmhw8cpUKZYm6NgcZBBU49M966usTxNasLaPVLdS01hlnVRkyQn/WL7nADAdygHeplFNaCcVYhopEdZEV0YMrDIYHII9aWsDEKKKKAKOomd7nTre3uWthc3XlSSoqswXy3IxuBH3lXtV7/hGbv/oYLz/vzD/8RVHVDsNhL/zz1C3/APHpFT/2auvraCTRrFJo57/hGbv/AKGC8/78w/8AxFH/AAjN3/0MF5/35h/+IroaKvlXYqyOe/4Rm7/6GC8/78w//EUf8Izd/wDQwXn/AH5h/wDiK6GijlXYLI57/hGbv/oYLz/vzD/8RR/wjN3/ANDBef8AfmH/AOIroaKOVdgsjnv+EZu/+hgvP+/MP/xFH/CM3f8A0MF5/wB+Yf8A4iuhoo5V2CyOe/4Rm7/6GC8/78w//EUf8Izd/wDQwXn/AH5h/wDiK6GijlXYLIwU8L7yBfatfXUfePKRK31KKG/WtuGGO3hSGCNYoo1CoiKAqgcAADoKfTZJEiiaSVgiICzMxwAB1JoskM5D4meKv+EZ8LuttJtv73MNvg8qMfM/4A/mRXhfhTw9N4n8SW2mQ5CO26aQD/Vxj7zf0HuRVvx14nfxX4onvFJ+yx/urVD2jB6/U9fxx2r1v4S+FP7D8Of2ldx7b3UQHwRykX8I/HqfqPSmB3VrbQ2VnDa2sYjhhQRxoOiqBgCpaKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDzjxZ/yWbwr/wBc2/m1ej15x4v4+MXhMjrsb+bV6PQAUUUUAFFFFABRRRQB89/F3Rv7L8cy3Ma4h1CMTrjpu6MPrkZ/4FXoPwa1r+0PCD6dI2ZdOlKgf9M3yy/ruH4U/wCMWhf2n4PF/EuZtNk8zgc+W3DD/wBBP/Aa81+FevjRPG0CTPtt74fZpM9ASfkP/fWB9CaAPcfFX/IFi/7CFl/6VRVs1jeKv+QLF/2ELL/0qirZrV/wl6v9CF8b9F+oUUUVkWFFFFABRRRQByUEH9l6hPpRGIkHm2n/AFxJ+6P9w/L9NnrVyrPiOykmskvbRC93YsZUResi4+eP8R0/2gvpVOGaO4t45oHDxSKHRh0YEZBrCaszKSsx9FFFQQZ2vnZossv/ADxeOb/vh1b+ldlXHa9EZvDmpRjq9rKB9dhrrLaYXFpFMOkiK4/EZransaw2JaKKK0LCiiigAooooAKKKKACiiigArzP4xeLP7O0ldBspMXN6u6cqeUi9P8AgR4+gPrXfazq1toWjXOpXzbYbdCzY6seyj3JwB9a+YNX1O88Sa/PfXAMlzdy8IvOM8Ko+gwBQBu/DjwofFPiiNbhN1haYluSRwwz8qf8CP6A19IAYGBwK5vwJ4XTwp4YhtGAN3L+9unHdyOmfQDj8M966SgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPOPGPHxg8JH1DD9TXo9eceM/8AkrnhH/gX8zXo9ABRRRQAUUUUAFFFFAEdxbxXdrLb3CCSGZDG6HoykYI/KvlnxDo8/hzxJd6bKWDW0pCP0LL1VvxGDX1VXl3xm8Km902LX7NMzWY8u5AHLRE8N/wEn8j7UAa1h4jXxR8ObG+Zgblb+yiuQO0i3UWT+PB/Gu7r5e8N61qenzfYrC4WKC6uIHlMibkQxyK6ufYEc+1fTltcQ3VtHPazpcROMrLGwZXHqCODW0reyjr1f6EK/O/l+pLRRRWJYUUUUAFFFFABXKCD+ytYn07pBLuubT2Un50/4Cxz7B1HaurrK8Q2El5p4mtF3Xlo3nQD++QMFP8AgSkj6kHtUyV0Jq6KdFRW1xHd2sVxAd0cqhlPsalrnMBk0YmgkjPR1Kn8RWh4YlM/hLSZG+81lCW+uwZ/WqVT+ED/AMUtap/zyaSH/viRl/pWtM0gbVFFFamgUUUUAFFFFABRRRQAUUVyXxF8Xr4U8OMbdx/aF3mO2X+76v8Ahn8yKAPOvi/4v/tPVRoVjJm1snzOVPEkvTH0Xp9SfQVJ8HPCP27UW8QX0ebe0bbbBhw8vdv+A/zPtXB6Bot34m8QW+nWuTLcPl5G52L1Zz9B+dfT+laZbaNpVvp9imy3t0CIPX3PuTyfc0AW6KKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA848a/wDJWPCH+8f/AEKvR6848b8fFTweR18wj/x4V6PQAUUUUAFFFFABRRRQAVBfBDp9yJohNGYm3REZDjByv49KnooA5Xwjo1jo/huzTT4kXzYUkkkA5kYjOSevfikvtTh8O67Z+VDI41MvG1tBtBkkABDgMQN2MgnOT8vXArQbS9RsWKaS9q9p/BBcblMPsGGcr6Ajj1xgDw/4jX/iJvE4h19Vt3tubYW5Ij25++hPJzjr1yMcYwOSNKanc354paq5674i8b3WiaSbyLwzqUreYiBJNig7jjqpY59OK19H8QLqlvam5sbvTbm5V2S1u49r4TbuPHQfMOuD7Vx3w3+JKa5FHpOuSqmpKNsUrcC5H/xft3rrrkhvHOmgn7mn3R/EyQY/QGuunTk5u8tLP8iq1ei6KjCklK+93t2tsbVFFFBzBRRRQAUUUUAcrLB/Zeuy2nS2vN1zb+ivn94n5kOPXc392rNX9e059R0wi2wLuBhPbMTgCRc8E9gwJU+zGsqzukvbOO4iBCyLnawwVPcEdiDwR6isJqzuZSVncmqTwkcaXdRf88r+4H/fUhf/ANnqOl8Lnbc61F6XocfRoIv6g06e4Q3OgooorY1CiiigAooooAKKKKAIL6+t9NsJ729lEVvAheRz2Ar5k8XeJrjxX4hm1GfKx/cgiJ/1cY6D69z7k12HxZ8cf2tenQtLlzZWz/6Q6niaQdvdV/U/QGoPhR4KOuaqNY1GPOn2b/u1YcTSjkD6DqffA9aAO9+Fng3/AIRzQ/t99Ht1G+UFgw5ij6hPY9z+A7V3lFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHnHjnj4peDienmn/ANCFej15x47/AOSneDf+ux/9CWvR6ACiiigAooooAKKKKACiiigArC8WeE7HxdpDWd6NkqZaC4UZaJvX3B7jv+RrdooA+Wta8Mat4d11dNu7d/tDMPIaIEibngoe/wDOvW/DGl6/a6tba74m0/7XewWn2VXjuF8zZnIZlIwzgEjO7kHpnmuu8SwRE6XeXCKYrO9EjuVB2Ao6A57AMykn2z2q7WFTEVKTtDqi404zXvFq2uYry2Se2ffG4yDjH1BB5BB4IPINS14bqXxLvtD8Z6lFo1zHLpUk4JUxCTa2AHZORnJBOM4P45roY9Q8Ra7dtr3h7xbbyadbWm64to7X97ldzFfIZiNx6bty57HjNVzysrRbv6f5nVSw1OpfmqxjpfXm+7SP5XPUaKyvDOrvr3hmw1SWBrd7qIO0bDGD6jk8HqPYitWt5RcJOL3Rwxakk0FFFFSMK5e7g/svX3QDFtqJMsfoswGXX/gQ+ce4euoqhrWnHVNLkgjYRzqRJbyEcJIvKk+2eCO4JHelJXVhNXRm03w+dniPV4v70VvL+fmL/wCyVDY3QvbNJ9hjY5Dxt1jcHDIfcMCD9KfpR2eMZl/57WCn/viQ/wDxysYfEZx3Omooorc1CiiigAooooAK85+KfjwaHYto2lTf8TK4X966Hm3Q+/Zj29Bz6VsePvHVv4Q0zZEVl1OdT5EJ/hH99vYfqfxI8AtLXUvE+vLDDvu7+8lJLMeWJ5LE9gOpPagC74Q8LXXi3Xo7G3ykK/PcTY4iTufqegHr+NfS2m6da6RpsFhYRCK3gQIiD09fcnqTWV4P8J2nhHQ1s7bEk74a4nxzK/8AgOw/qTW/QAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUU15EjXdIwVcgZJwOeKAPOvH3HxK8GEdftB/9DSvR684+IHHxH8Fn1uSP/H0r0USIZTEHUyKoYrnkA5wcfgfyNADqKKKACiiigAooooAKKKKACiiigBGUMpVgCpGCCOtZJ8MaaWwRceTjH2f7VJ5WPTZuxj26Vr0UrJgeQeMvg4Sz3vhI9eWsZG/9AY/yP59qp/DfwHLKJdV1Ke8sZYpWgSGFzE+Rw249cZ4x7V7XXPyB9EubppopZbK4mMySQxNIYmb7ysqgnG7JBAxyQcYBOdXm5fdKja+pBcXo8I2Yu7m6ml0qMqkqyDe1uCQoZSBkgEgFeeORjGDrx69pU2mtqEOo28loiGRpUkDAADJ6enpXFePp9T1nwjc2ugaVdXcchXz5TEVwoOflVsMxyB0BxXhS+ZayOu3y2wUdWX8CCDUU3V5dfxN4qhzfvG/kl/mfVumazpus2/n6VfQXcfGTDIG2/UdQfY1drwjwH8SNJ8MW/wBkutBigDYD3dmMyP8A7wY5P/fX0FewaL4r0TxCgOk6jDO5HMRbbIPqp5raPNb3tyK/sfaP2F+Xpe1/nY16KKKoxOZ1GD+zPEHmLxbakfwSdR/7Moz9UPdqZbHy/GVg3/PS0uI/x3RMP/QTW7q2nrqmmS2pby2YBo5AOY3ByrD6EA1y1pdtPrGhTSp5UwupbeePP+rcQybh9NycHuMHvWbVpXIatK52tFFFaFhRRR0oAK5Txx48svB9jt+W41KVcw22en+03ov6nt3IwvG3xZstISSx8OvHe3/3WnHMUP4/xH26evpXjUceq+KNc2oJr/ULp+STlmPqT2A/ICgAnn1TxRrxkk8y91C8kwABksewA7AfkAK998AeBIPCGnGWfbNqlwo86UdEH9xfb1Pc/hTfAfw+tPCNqLi423OqyLiSbHEY/up7e/U/pXZUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABUN5axX1jPaXK7oZ42jceqsMH+dTUUAfOeteKNXsdf0221gC5vPDly6pK5OZgGUru9fu9e4I+p9f8AhzFey+GjrGryNLfatIbl2YYwnRFHouBkD/ariPif4PkvviBpUlouF1hlhkYD7rrgFv8AvjB/4Ca9gt4I7W1it4FCRRIERR2UDAFAElFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABWF4g8GaF4mQ/2pZKZsYFxF8kg/wCBDr9DkVu0UAeI678E9Std0ugXkd9H1EM2I5PoD90/pXnuo6TqWiXQi1Ozns5gcr5iFc+4Pf6ivrCobuztr+3aC9t4riFvvRyoGU/gaAPnHR/iT4o0ZVSHUnuYh/yyuh5o/M/MPwNdppvx0YKF1jRgT3ktZcf+Ot/8VXUat8I/C+pbmgt5dPkP8VtJxn/dbI/LFcVqfwP1SFi2kalbXSf3Z1MTfpkH9KAO2sfi74TvAPOup7Jj/DcQN/NdwrN1bxJoJ8Tabf6bq9nLBc3cX2hRKAY5ANgkIPIBQkEngbF9a82vfhl4uscl9IkmUfxQOsmfwBz+lZEnhjX4v9boepJ/vWkg/pQB9NDXtIKbxqtkV/vC4TH86p3XjPw1ZqWn13T+OyXCu35KSa+axoerM21dLvC3oLd8/wAqt2/g7xJduFg0LUDnu1syj8yAKAPYtW+M3hyxUjTVuNSk7bEMafiW5/IGvMfE/wASde8Sq8DzCysm4NtbkgMP9purfy9qvaZ8HvFF7Iv2uKDT4z1aaUMcfRc/rivQvD3wf0LSHWbU2fVZ15AlXbED/uDr+JI9qAPJ/CngTWPFswazi8izBw93KMIPUD+8fYfjivevCvg7S/CVj5Onx753H765kHzyH+g9h/PmtyONIY1jiRURRhVUYAHoBTqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAI5LeKaSGSWNWeBy8bEcoxUrkfgxH41JRRQAUUUUAFFUNQ13TNLkSK+vI45pCFjhB3SOT0CoMsfwFXgcqDgjI6HtQAtFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRTZH8uNn2s20ZwoyT9BVPTdb03V1Y6bewzshw6K2HQ+jKeVPsRQBeooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAILx7mOzkawhjmuAvyRyyFFY+7AHH5V4t428S/ES3Miahby6VadN1kuUI/66jJ/UfSvcKCAQQRkHqDQB86/D+fxCNXubzw7pdjqmoKuWkvZR5kYPUqDIvXoTz6d+fQ/7a+K/wD0LOlf9/V/+PV01z4H0SXUY9Rsrc6bfxtuS5sj5Zz7r90575BzXQLkKNxycckDGaAPOf7a+K//AELOlf8Af1f/AI9R/bXxX/6FnSv+/q//AB6vR6KAPOP7a+K//Qs6V/39X/49R/bXxX/6FnSv+/q//Hq9HooA84/tr4r/APQs6V/39X/49R/bXxX/AOhZ0r/v6v8A8er0eigDzj+2viv/ANCzpX/f1f8A49R/bXxX/wChZ0r/AL+r/wDHq9HooA84/tr4r/8AQs6V/wB/V/8Aj1H9tfFf/oWdK/7+r/8AHq9HooA84/tr4r/9CzpX/f1f/j1H9tfFf/oWdK/7+r/8er0eigDzj+2viv8A9CzpX/f1f/j1H9tfFf8A6FnSv+/q/wDx6vR6KAPOP7a+K/8A0LOlf9/V/wDj1H9tfFf/AKFnSv8Av6v/AMer0eigDzj+2viv/wBCzpX/AH9X/wCPUf218V/+hZ0r/v6v/wAer0eigDzj+2viv/0LOlf9/V/+PUf218V/+hZ0r/v6v/x6vR6KAPOP7a+K/wD0LOlf9/V/+PUf218V/wDoWdK/7+r/APHq9HooA84/tr4r/wDQs6V/39X/AOPUf218V/8AoWdK/wC/q/8Ax6vR6KAPOP7a+K//AELOlf8Af1f/AI9R/bXxX/6FnSv+/q//AB6vR6KAPOP7a+K//Qs6V/39X/49R/bXxX/6FnSv+/q//Hq9HooA84/tr4r/APQs6V/39X/49R/bXxX/AOhZ0r/v6v8A8er0eigDzj+2viv/ANCzpX/f1f8A49R/bXxX/wChZ0r/AL+r/wDHq9HooA84/tr4r/8AQs6V/wB/V/8Aj1H9tfFf/oWdK/7+r/8AHq9HooA84/tr4r/9CzpX/f1f/j1H9tfFf/oWdK/7+r/8er0eigDzj+2viv8A9CzpX/f1f/j1H9tfFf8A6FnSv+/q/wDx6vR6KAPOP7a+K/8A0LOlf9/V/wDj1ebeObjXY/Ecd3ren2ek6mybibCUbn9Gba7YPvxn3xX0dIrNEyxvscggNjO0+uKwbDwRoVjevfSWn26+kbe93eHzZGb154H4AUAeceCPEnxFujGtvaNqln/z1vl2AD2kOCf/AB6vY7dpmt42uo0jmKjekbl1U+gJAz+QqTpRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFcf441vUvDer+GtShuduiyagLLVITGpGJhtilLEZULJtBwRndzWS/iXxBqV/42vNI1PT7LTtH2afYvqWEtluVAa4mkfbuwu4KBnblelAHo1Z+ia9pviPTft+jXP2m2814vM8tk+dGKsMMAeCCK8n0Xx/eQfEfQNJtPH0HjC01OSWC7jTT44RbkRlldJIxg8jG0k8fnVPwXr2paP4W8IW+m3Pkxal4rvLa6Xy1bzI/MmO3JBxyByMGgD3SivM/GHj7UPCnjvWlZ/P03T/AAp/aSWexQGuPtDRglsbsEBQRnHfGa4+y+LVzpkujX9z8QdO8QveXMUWoaLFYrEIFlIBMLqNxMZP8RO4A9KAPfKK5v4geJLnwl4E1HWbC3S4u4RHHbxyH5TJJIsalunAZwTyOBXLXl3408D6l4futc8SReIbLVNRh027tmsY7fyHmOFkiZMEgN1DZyPfkAHY2/jPQbvxXN4btb7ztVgGZoY4JGWPjOGkC7Acdi2fatyvLvhHpWrWeveMZr/xDNqEUetzwSQvaxRiWbyoD55KqCDj5do+XvjNXfEHjS/8J+MfEcWp3Qk05fD51XTo3RVEckRKSRhgAWLFozgk9eMUAeiUV47ofjfxXdeGtE0LUbsL4tl8QnTb6UQxhhDGPPkcJt2j9ztXp3z1rnpPi/eala6nrkPxA03RZoZpfsHh6WxWQSpGSFE0hG8M+P4SMZH0oA9zOu6cPEq+Hzcf8TRrQ3og2N/qQ4Qtuxt+8QMZz7VoV5Fc/Fa8j1RNXjz/AGS3ghtcGnlV/wCPnzVUAvjd/Ft6474pmr3fxG8P+HdF1268V290NQvrOO9shpsSLbJNIoKxPyTjOz5skgkggigD1DT9e03VdS1GwsLnzbnTJViu4/LZfKdl3AZIAPBzxmrclzBDNDDNPHHLOxWJGcBpCAWIUdyACeOwNeQaNpPifVfiT8QV8OeJU0GOO/gJZbFLh5ZDbrgHfwFHsMnPUY5xE1LXvHeufCbXTrTaZdahDfKRBaxusUkcTiSQBwc+YoCkHIXqMGgD3+isTxjqOsaR4R1HUPDtpaXd9a28kqRXcrIh2oW/hBLHgfLlc/3l61ztl8RzfeIPCumxW8aprOmPe3NwwOyBxDHKIwc9cPuIPQFfWgDvaK5jw34kvr24sdM1qO1XUptN+3ym3SZF2mTau0MhUAjBIMm8H+HHNdPQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAGR4r8PW/izwnqOhXjmOO+gMYkC5MbdVcDuVYBh9K5mX4WWs3wn/4QuTU5i5YTyaiIhuluPN80yMhJDAv/AAknjjPeu9ooA89j+HOvXXiLQdY17xj/AGhLolwZILeLTEt4SjIUYbVfO45GGJIGD8vNRj4TPF4PsNKs9fkttR03VZNUstRS0UiOR3dtrRMxDLhyOozgHjpXo1FAHnlt8LJLrXNT1Pxbr8muvquknS7mM2qwKEL7gY9rHYB2HJySd3ap7HwJ4njn0+DUvH99daVp8qOlvBaLbzTBPupLOrZdexAA3d67yigDK8T+HbHxb4ZvdD1UP9lvE2u0bYZCCGVlPqGAI9xXLW3w81i81XSrjxh4vl1200edbm0tVsUt90yjCSSsGJcr1GNvPPtXfUUAYfhvw3/wj1xrkv2r7R/a2qSahjy9nlbo402dTux5ec8denFZXj34eW/ju40SWe9a0/sy782QCLf9ohJUyQnkYDbE556dDXY0UAcbbfDu2t/i1deNzeNI09r5KWRj+WKUqiNKGz1KRquMfjWcfhvrmnRXem+FfGtxo2h3UryCyWxSWS28xiziGYsCgJLEcHGeOea9DooA4PWvAdot9da1fzXuq2cPheXRpbAJ5tzdJuEhcSFhukO3ABHLHORXljXMniOPwv4d0Pxvd+I/s2p2jx6WdL+zy2kMTAs11J32KMdsnn5jX0fRQBz3h/wr/YXiPxFqv2zz/wC27mO48rytvk7IwmM5O7OM5wK5ay+E11pXh7wjaaV4jEGo+F3nMN69gHSZZgwdTGX44bAO49K9KooAr6haC/025tGbaLiF4ixXONwIzjv1rjYvhXp0UHha3F9cND4eikiIZVLXiuioVkP90qgBXHK4XIA57qigDGsdEuLXxdq2sz3sc8d9DBDDB5BV7dYw3G/cQwLOzfdGM9TWzRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB//Z)\n",
        "\n",
        "Reference \n",
        "https://developers.google.com/machine-learning/crash-course/reducing-loss/learning-rate "
      ],
      "metadata": {
        "id": "RQEhDz4uAj1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, a simple XGB\n",
        "fit <- xgboost(data = dtrain,\n",
        "               nrounds = 100,\n",
        "               objective = \"binary:logistic\",\n",
        "               eta = 0.5,\n",
        "               max_depth = 9,\n",
        "               eval_metric = \"auc\",\n",
        "               verbose = 0)\n",
        "\n",
        "df_train_pred$pred_y_XGB_init <- predict(fit, dtrain)\n",
        "df_test_pred$pred_y_XGB_init <- predict(fit, dtest)\n",
        "df_train_pred_bin$pred_y_XGB_init <- ifelse(df_train_pred$pred_y_XGB_init > 0.1, 1, 0)\n",
        "df_test_pred_bin$pred_y_XGB_init <- ifelse(df_test_pred$pred_y_XGB_init > 0.1, 1, 0)"
      ],
      "metadata": {
        "id": "UUHljSZu4rOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(df_test_pred)"
      ],
      "metadata": {
        "id": "baIr-nTGbQSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate weights based on ratio of classes\n",
        "pos_weight <- sum(y_train == 0) / sum(y_train == 1)\n",
        "print(pos_weight)\n",
        "fit <- xgboost(data = dtrain,\n",
        "               nrounds = 100,\n",
        "               objective = \"binary:logistic\",\n",
        "               eta = 0.5,\n",
        "               max_depth = 9,\n",
        "               eval_metric = \"auc\",\n",
        "               scale_pos_weight = pos_weight,\n",
        "               verbose = 0)\n",
        "\n",
        "df_train_pred$pred_y_XGB_balanced <- predict(fit, dtrain)\n",
        "df_test_pred$pred_y_XGB_balanced <- predict(fit, dtest)\n",
        "df_train_pred_bin$pred_y_XGB_balanced <- ifelse(df_train_pred$pred_y_XGB_balanced > 0.5, 1, 0)\n",
        "df_test_pred_bin$pred_y_XGB_balanced <- ifelse(df_test_pred$pred_y_XGB_balanced > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "Msl-7khZ7Gny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiet.setting = TRUE\n",
        "roc_train <- roc(df_train_pred$y_train, df_train_pred$pred_y_XGB_balanced, quiet=quiet.setting)\n",
        "roc_test <- roc(df_test_pred$y_test, df_test_pred$pred_y_XGB_balanced, quiet=quiet.setting)\n",
        "roc_train\n",
        "roc_test"
      ],
      "metadata": {
        "id": "FYqybU0L4Xuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights \n",
        "Since the AUC here is near 1.0, (we wish) we can consider this to be a good model. But, clearly we're overfitting, per the test data AUC of 0.58. In the interest of time, let's fast forward to choosing a different hyperparameters to improve on the gap."
      ],
      "metadata": {
        "id": "d9vHtLUYIVZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's go with some pet hyperparameters\n",
        "fit <- xgboost(data = dtrain,\n",
        "               nrounds = 100,\n",
        "               objective = \"binary:logistic\",\n",
        "               eta = 0.1,\n",
        "               max_depth = 6,\n",
        "               subsample = 0.6,\n",
        "               colsample_bytree = 0.6,\n",
        "               verbose = 0)\n",
        "\n",
        "df_train_pred$pred_y_XGB2 <- predict(fit, dtrain)\n",
        "df_test_pred$pred_y_XGB2 <- predict(fit, dtest)\n",
        "df_train_pred_bin$pred_y_XGB2 <- ifelse(df_train_pred$pred_y_XGB2 > 0.5, 1, 0)\n",
        "df_test_pred_bin$pred_y_XGB2 <- ifelse(df_test_pred$pred_y_XGB2 > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "YFXORABLi9Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiet.setting = TRUE\n",
        "roc_train <- roc(df_train_pred$y_train, df_train_pred$pred_y_XGB2, quiet=quiet.setting)\n",
        "roc_test <- roc(df_test_pred$y_test, df_test_pred$pred_y_XGB2, quiet=quiet.setting)\n",
        "roc_train\n",
        "roc_test"
      ],
      "metadata": {
        "id": "L4KdmVnEoFYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importance matrix\n",
        "\n",
        "The importance matrix in XGBoost is a tool that helps to measure the relative importance of each feature in the model. It is calculated based on the contribution of each feature to the reduction of the loss function during training. There are two types of importance matrices in XGBoost: weight-based and gain-based. The importance matrix can be used for feature selection or dimensionality reduction, and it can be visualized using a bar chart or heatmap to make it easier to interpret the results."
      ],
      "metadata": {
        "id": "F7m-UhbpGt4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_matrix <- xgb.importance(colnames(dtrain), model = fit)\n",
        "importance_matrix <- subset(importance_matrix, select = c(Feature,Gain))\n",
        "  \n",
        "xgb.plot.importance(importance_matrix) \n",
        "top_15_features <- head(importance_matrix$Feature, 15)"
      ],
      "metadata": {
        "id": "OycN34Zs-vX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_15_features)"
      ],
      "metadata": {
        "id": "OnA6a5A2qlQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tmp.train <- data.frame(x_train, df_train_pred)\n",
        "df.tmp.test <- data.frame(x_test, df_test_pred)\n",
        "colnames(df.tmp.train)"
      ],
      "metadata": {
        "id": "7RaDoFfgfx1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's build prediction bands for lift table review\n",
        "df.tmp.train <- df.tmp.train %>%\n",
        "  mutate(freq_nt = ntile(pred_y_XGB2/ee_pd,10))\n",
        "df.tmp.test <- df.tmp.test %>%\n",
        "  mutate(freq_nt = ntile(pred_y_XGB2/ee_pd,10))"
      ],
      "metadata": {
        "id": "2W_rEuhugSYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Again, in case we need variable binning\n",
        "var.group = \"freq_nt\"\n",
        "df.tmp.train <- df.tmp.train %>%\n",
        "  mutate(nt = ntile(eval(parse(text = var.group)), 10))\n",
        "df.tmp.test <- df.tmp.test %>%\n",
        "  mutate(nt = ntile(eval(parse(text = var.group)), 10))"
      ],
      "metadata": {
        "id": "L58kR_-5gn8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var.curr = \"freq_nt\"\n",
        "avse.plot.classification(var=var.curr,data=df.tmp.train,actual=\"y_train\",pred=\"pred_y_XGB_balanced\",weight=\"ee_pd\",lt_text=\"exposures\",rt_text=\"freq\")\n",
        "avse.plot.classification(var=var.curr,data=df.tmp.test,actual=\"y_test\",pred=\"pred_y_XGB_balanced\",weight=\"ee_pd\",lt_text=\"exposures\",rt_text=\"freq\")"
      ],
      "metadata": {
        "id": "uI2ca8YMlXYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hihI3Y9E4Pe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving GLM using XGboost insights \n",
        "\n",
        "In this secion, we will try to improve the GLM output based on results from Xgboost. \n",
        "\n",
        "\n",
        "1. Reduce number of features based on XGboost ( feature selection) \n",
        "2. Use appropriate weight function and evaluation metric ( AUC) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "46j0cQ26Io_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_top15 <- x_train[, c(top_15_features)]\n",
        "x_test_top15 <- x_test[, c(top_15_features)]\n",
        "#print(x_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "N01Y9wb7VD9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(x_test_top15)"
      ],
      "metadata": {
        "id": "EFcivmtzo6t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a GLM\n",
        "fit <- glm(y_train ~ ., data = x_train_top15, family = \"binomial\")\n",
        "df_train_pred$pred_y_GLM2 <- predict(fit, newdata = x_train_top15, type = \"response\")\n",
        "df_test_pred$pred_y_GLM2 <- predict(fit, newdata = x_test_top15, type = \"response\")\n",
        "df_train_pred_bin$pred_y_GLM2 <- ifelse(df_train_pred$pred_y_GLM2 > 0.1, 1, 0)\n",
        "df_test_pred_bin$pred_y_GLM2 <- ifelse(df_test_pred$pred_y_GLM2 > 0.1, 1, 0)"
      ],
      "metadata": {
        "id": "FOi7SaRjYbHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduce Exposure as a \"base_margin\"\n",
        "\n",
        "\n",
        "* Introducing exposure as a \"base_margin\" in XGBoost provides the model with prior knowledge about the expected value of the target variable for each training instance.\n",
        "* Exposure is the amount of risk that an insurance policy or portfolio of policies is exposed to over time, measured in units like person-years or vehicle-years.\n",
        "* Setting the \"base_margin\" parameter to the logarithm of the exposure can help the model learn faster and converge to a better solution, but can also introduce bias if the exposure is not a good proxy for the target variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "O5N9xmkz4ZVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train2 <- x_train[, -which(names(x_train) == \"ee_pd\")]\n",
        "x_test2 <- x_test[, -which(names(x_test) == \"ee_pd\")]\n",
        "\n",
        "dtrain_exp <- xgb.DMatrix(data = as.matrix(x_train2)\n",
        "                        , label = y_train\n",
        "  )\n",
        "setinfo(dtrain_exp, \"base_margin\", log(x_train$ee_pd))\n",
        "\n",
        "dtest_exp <- xgb.DMatrix(data = as.matrix(x_test2)\n",
        "                       , label = y_test\n",
        "  )\n",
        "setinfo(dtest_exp, \"base_margin\", log(x_test$ee_pd))\n",
        "\n",
        "# create a dataset with no exposure adjustment, since test data may not have exposure as input\n",
        "# Note that we are not using the Setinfo parameter\n",
        "dtest_noexp <- xgb.DMatrix(data = as.matrix(x_test2)\n",
        "                       , label = y_test\n",
        "  )\n",
        "watchlist <- list(train = dtrain_exp, test = dtest_noexp)\n"
      ],
      "metadata": {
        "id": "txSJEFGd4p6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiet.setting = TRUE\n",
        "# Define hyperparameters\n",
        "set.seed(123)\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  eval_metric = \"auc\",\n",
        "  eta = 0.05,\n",
        "  gamma = 0.1,\n",
        "  lambda = 0.1 , \n",
        "  max_depth = 6,\n",
        "  subsample = 0.6,\n",
        "  colsample_bytree = 0.6\n",
        "  \n",
        ")\n",
        "#scale_pos_weight = pos_weight\n",
        "#  min_child_weight = 2 , \n",
        "#   alpha = 0.4, \n",
        "\n",
        "\n",
        "num_round <- 1000\n",
        "\n",
        "# Train the model with early stopping; so giving a large num_round is fine. \n",
        "# Early stopping is a mechanism by which xgboost detects if the test/validation data is getting more error.\n",
        "# early_stopping_rounds = 20, is the number of iterations for which the algorithm will wait before calling it.\n",
        "model_xgbexp <- xgb.train(\n",
        "  params = params,\n",
        "  data = dtrain_exp,\n",
        "  nrounds = num_round,\n",
        "  watchlist = watchlist,\n",
        "  early_stopping_rounds = 20,\n",
        "  verbose = 0\n",
        ")\n",
        "\n",
        "\n",
        "df_train_pred$pred_y_XGB3 <- predict(model_xgbexp, dtrain_exp)\n",
        "df_test_pred$pred_y_XGB3 <- predict(model_xgbexp, dtest_exp)\n",
        "df_test_pred$pred_y_XGB3_noexp <- predict(model_xgbexp, dtest_noexp)\n",
        "\n",
        "df_train_pred_bin$pred_y_XGB3 <- ifelse(df_train_pred$pred_y_XGB3 > 0.5, 1, 0)\n",
        "df_test_pred_bin$pred_y_XGB3 <- ifelse(df_test_pred$pred_y_XGB3 > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "vbaEtXkt4Yvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiet.setting = TRUE\n",
        "roc_train <- roc(df_train_pred$y_train, df_train_pred$pred_y_XGB3, quiet=quiet.setting)\n",
        "roc_test <- roc(df_test_pred$y_test, df_test_pred$pred_y_XGB3, quiet=quiet.setting)\n",
        "roc_train\n",
        "roc_test"
      ],
      "metadata": {
        "id": "FuoQTryRQlkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Model  | Description | Color\n",
        "-------------------|------------------|------------------\n",
        "pred_y_GLM_init       | Initial GLM  | blue \n",
        "pred_y_XGB_init       | Initial XGboost | purple \n",
        "pred_y_XGB2       | XGBoost with parameters | green \n",
        "pred_y_GLM2       | GLM optimized with XGboost insights | red \n",
        "pred_y_XGB3       | XGBoost with exposure as prior | green "
      ],
      "metadata": {
        "id": "wdvheayBRgO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ROC curve for training data\n",
        "quiet.setting = TRUE\n",
        "roc_curve1 <- roc(df_train_pred$y_train, df_train_pred$pred_y_GLM_init, quiet=quiet.setting)\n",
        "roc_curve2 <- roc(df_train_pred$y_train, df_train_pred$pred_y_XGB_init, quiet=quiet.setting)\n",
        "roc_curve3 <- roc(df_train_pred$y_train, df_train_pred$pred_y_XGB2, quiet=quiet.setting)\n",
        "roc_curve4 <- roc(df_train_pred$y_train, df_train_pred$pred_y_GLM2, quiet=quiet.setting)\n",
        "roc_curve5 <- roc(df_train_pred$y_train, df_train_pred$pred_y_XGB3, quiet=quiet.setting)\n",
        "\n",
        "\n",
        "plot(roc_curve1, col = \"blue\", type=\"l\", lty=1)\n",
        "lines(roc_curve2, col = \"purple\", lty=1)\n",
        "lines(roc_curve3, col = \"green\", lty=2)\n",
        "lines(roc_curve4, col = \"red\", lty=2)\n",
        "lines(roc_curve5, col = \"black\", lty=2)\n",
        "\n",
        "# Add a legend\n",
        "legend(\"bottomright\", legend = c(\"GLM1\", \"XGB1\", \"XGB2\", \"GLM2\",\"XGB3\"),\n",
        "       col = c(\"blue\", \"purple\",\"green\", \"red\",\"black\"), lty = c(1, 1, 2, 2))"
      ],
      "metadata": {
        "id": "jwsTDAx60xwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ROC curve\n",
        "quiet.setting = TRUE\n",
        "roc_curve1 <- roc(df_test_pred$y_test, df_test_pred$pred_y_GLM_init, quiet=quiet.setting)\n",
        "roc_curve2 <- roc(df_test_pred$y_test, df_test_pred$pred_y_XGB_init, quiet=quiet.setting)\n",
        "roc_curve3 <- roc(df_test_pred$y_test, df_test_pred$pred_y_XGB2, quiet=quiet.setting)\n",
        "roc_curve4 <- roc(df_test_pred$y_test, df_test_pred$pred_y_GLM2, quiet=quiet.setting)\n",
        "roc_curve5 <- roc(df_test_pred$y_test, df_test_pred$pred_y_XGB3, quiet=quiet.setting)\n",
        "roc_curve6 <- roc(df_test_pred$y_test, df_test_pred$pred_y_XGB3_noexp, quiet=quiet.setting)\n",
        "\n",
        "plot(roc_curve1, col = \"blue\", type=\"l\", lty=1)\n",
        "lines(roc_curve2, col = \"purple\", lty=1)\n",
        "lines(roc_curve3, col = \"green\", lty=2)\n",
        "lines(roc_curve4, col = \"red\", lty=2)\n",
        "lines(roc_curve5, col = \"black\", lty=2)\n",
        "lines(roc_curve6, col = \"cyan\", lty=2)\n",
        "# Add a legend\n",
        "legend(\"bottomright\", legend = c(\"GLM1\", \"XGB1\", \"XGB2\", \"GLM2\",\"XGB3\",\"XGB3_noexp\"),\n",
        "       col = c(\"blue\", \"purple\",\"green\", \"red\",\"black\",\"cyan\"), lty = c(1, 1, 2, 2))"
      ],
      "metadata": {
        "id": "Mo7nShIL18L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our statline builder, to make things a little easier"
      ],
      "metadata": {
        "id": "tpjsRlIH_IXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quiet.setting = TRUE\n",
        "model_names <- c(\"GLM_init\", \"XGB_init\", \"XGB2\", \"GLM2\", \"XGB3\",\"XGB3_noexp\")\n",
        "\n",
        "auc_GLM_init <- auc(df_train_pred$y_train, df_train_pred$pred_y_GLM_init, quiet=quiet.setting)\n",
        "auc_XGB_init <- auc(df_train_pred$y_train, df_train_pred$pred_y_XGB_init, quiet=quiet.setting)\n",
        "auc_XGB2 <- auc(df_train_pred$y_train, df_train_pred$pred_y_XGB2, quiet=quiet.setting)\n",
        "auc_GLM2 <- auc(df_train_pred$y_train, df_train_pred$pred_y_GLM2, quiet=quiet.setting)\n",
        "auc_XGB3 <- auc(df_train_pred$y_train, df_train_pred$pred_y_XGB3, quiet=quiet.setting)\n",
        "auc_XGB3_noexp <- auc(df_train_pred$y_train, df_train_pred$pred_y_XGB3, quiet=quiet.setting)\n",
        "auc_train <- c(auc_GLM_init, auc_XGB_init, auc_XGB2, auc_GLM2,auc_XGB3,auc_XGB3_noexp)\n",
        "gini_train <- 2 * auc_train - 1\n",
        "\n"
      ],
      "metadata": {
        "id": "lBDykRFg_M13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_GLM_init <- auc(df_test_pred$y_test, df_test_pred$pred_y_GLM_init, quiet=quiet.setting)\n",
        "auc_XGB_init <- auc(df_test_pred$y_test, df_test_pred$pred_y_XGB_init, quiet=quiet.setting)\n",
        "auc_XGB2 <- auc(df_test_pred$y_test, df_test_pred$pred_y_XGB2, quiet=quiet.setting)\n",
        "auc_GLM2 <- auc(df_test_pred$y_test, df_test_pred$pred_y_GLM2, quiet=quiet.setting)\n",
        "auc_XGB3 <- auc(df_test_pred$y_test, df_test_pred$pred_y_XGB3, quiet=quiet.setting)\n",
        "auc_XGB3_noexp <- auc(df_test_pred$y_test, df_test_pred$pred_y_XGB3_noexp, quiet=quiet.setting)\n",
        "auc_test <- c(auc_GLM_init, auc_XGB_init, auc_XGB2, auc_GLM2, auc_XGB3,auc_XGB3_noexp)\n",
        "gini_test <- 2 * auc_test - 1\n"
      ],
      "metadata": {
        "id": "_vbbaQs2I-SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data.frame(model_names, auc_train, gini_train, auc_test, gini_test)"
      ],
      "metadata": {
        "id": "GrLolqiJJFqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Observations\n",
        "\n",
        "\n",
        "*   XGBoost outperforms GLM \n",
        "*   GLM with importance features holds up with original GLM \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zW1HvkCKOObH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "end_time <- Sys.time()\n",
        "elapsed_time <- difftime(end_time, start_time, units = \"secs\")\n",
        "print(paste(\"Full Notebook Run took: \", round(elapsed_time/60, 2), \" minutes\"))\n"
      ],
      "metadata": {
        "id": "tAmA8Zvsmzk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can now work to move GLM toward XGB, or improve on XGB knowing we still have a gap between train and test.\n",
        "\n",
        "As for today, we will pause, and go for break. When we return, we will provide another case study."
      ],
      "metadata": {
        "id": "OhiTqxtIFAMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "sCjo3jhWVHUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time <- Sys.time()\n",
        "\n",
        "#train_idx <- createDataPartition(train_data, p = 0.5, list = FALSE)\n",
        "train_data_grid <- train_data %>% sample_frac(0.3, replace = FALSE)\n",
        "x_train_grid <- train_data_grid[, !names(train_data_grid) %in% \"claim_count_pd\"]\n",
        "y_train_grid <- train_data_grid$claim_count_pd\n",
        "\n",
        "dtrain <- xgb.DMatrix(data = as.matrix(x_train_grid)\n",
        "                        , label = y_train_grid\n",
        "  )\n",
        "pos_weight <- sum(y_train == 0) / sum(y_train == 1)\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "nrounds <- c(50,100,150)\n",
        "max_depth <- c(6,7,8)\n",
        "eta <- c(0.1,0.3, 0.5)\n",
        "gamma <- c( 0.1,0.3, 0.5)\n",
        "subsample <- c(0.6, 0.8)\n",
        "colsample_bytree <- c(0.6, 0.8)\n",
        "\n",
        "  eta = 0.2,\n",
        "  gamma = 0.1,\n",
        "  lambda = 0.5 , \n",
        "  alpha = 0.5, \n",
        "  min_child_weight = 2 , \n",
        "  max_depth = 7,\n",
        "  subsample = 0.6,\n",
        "  colsample_bytree = 0.8,\n",
        "\n",
        "  \n",
        "# Generate a grid of all possible hyperparameter combinations\n",
        "hyperparams <- expand.grid(\n",
        "  nrounds = nrounds,\n",
        "  max_depth = max_depth,\n",
        "  eta = eta,\n",
        "  gamma = gamma,\n",
        "  subsample = subsample,\n",
        "  colsample_bytree = colsample_bytree\n",
        ")\n",
        "\n",
        "results <- lapply(1:nrow(hyperparams), function(i) {\n",
        "  params <- as.list(hyperparams[i, ])\n",
        "  xgb.cv(\n",
        "    data = dtrain,\n",
        "    nfold = 2,\n",
        "    nrounds = params$nrounds,\n",
        "    max_depth = params$max_depth,\n",
        "    eta = params$eta,\n",
        "    gamma = params$gamma,\n",
        "    subsample = params$subsample,\n",
        "    colsample_bytree = params$colsample_bytree,\n",
        "    objective = \"binary:logistic\",\n",
        "    eval_metric = \"auc\",\n",
        "    scale_pos_weight = pos_weight\n",
        "  )\n",
        "\n",
        "  print(params)\n",
        "  print(max(xgb_cv$test_auc_mean))\n",
        "})\n",
        "\n",
        "# Extract the best hyperparameters from the results\n",
        "best_result <- max(unlist(lapply(results, function(x) x$test.auc.mean)))\n",
        "best_params <- as.list(hyperparams[which(unlist(lapply(results, function(x) x$test.auc.mean)) == best_result), ])\n",
        "\n",
        "\n",
        "end_time <- Sys.time()\n",
        "elapsed_time <- difftime(end_time, start_time, units = \"secs\")\n",
        "print(paste(\"XGboost Tuning took: \", round(elapsed_time/60, 2), \" minutes\"))"
      ],
      "metadata": {
        "id": "2kEsmhjCJZWl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}